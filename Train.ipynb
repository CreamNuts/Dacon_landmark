{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "use:  cuda\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 1440x720 with 2 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"603.474375pt\" version=\"1.1\" viewBox=\"0 0 1166.98125 603.474375\" width=\"1166.98125pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <metadata>\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2020-11-10T21:50:41.611855</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.3.2, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 603.474375 \nL 1166.98125 603.474375 \nL 1166.98125 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 43.78125 565.918125 \nL 551.053977 565.918125 \nL 551.053977 22.318125 \nL 43.78125 22.318125 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m2e7f4990e4\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"66.839101\" xlink:href=\"#m2e7f4990e4\" y=\"565.918125\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 1.0 -->\n      <g transform=\"translate(58.887539 580.516562)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n        <path d=\"M 10.6875 12.40625 \nL 21 12.40625 \nL 21 0 \nL 10.6875 0 \nz\n\" id=\"DejaVuSans-46\"/>\n        <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"159.070506\" xlink:href=\"#m2e7f4990e4\" y=\"565.918125\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 1.2 -->\n      <g transform=\"translate(151.118944 580.516562)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"251.301911\" xlink:href=\"#m2e7f4990e4\" y=\"565.918125\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 1.4 -->\n      <g transform=\"translate(243.350349 580.516562)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"343.533316\" xlink:href=\"#m2e7f4990e4\" y=\"565.918125\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 1.6 -->\n      <g transform=\"translate(335.581754 580.516562)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 33.015625 40.375 \nQ 26.375 40.375 22.484375 35.828125 \nQ 18.609375 31.296875 18.609375 23.390625 \nQ 18.609375 15.53125 22.484375 10.953125 \nQ 26.375 6.390625 33.015625 6.390625 \nQ 39.65625 6.390625 43.53125 10.953125 \nQ 47.40625 15.53125 47.40625 23.390625 \nQ 47.40625 31.296875 43.53125 35.828125 \nQ 39.65625 40.375 33.015625 40.375 \nz\nM 52.59375 71.296875 \nL 52.59375 62.3125 \nQ 48.875 64.0625 45.09375 64.984375 \nQ 41.3125 65.921875 37.59375 65.921875 \nQ 27.828125 65.921875 22.671875 59.328125 \nQ 17.53125 52.734375 16.796875 39.40625 \nQ 19.671875 43.65625 24.015625 45.921875 \nQ 28.375 48.1875 33.59375 48.1875 \nQ 44.578125 48.1875 50.953125 41.515625 \nQ 57.328125 34.859375 57.328125 23.390625 \nQ 57.328125 12.15625 50.6875 5.359375 \nQ 44.046875 -1.421875 33.015625 -1.421875 \nQ 20.359375 -1.421875 13.671875 8.265625 \nQ 6.984375 17.96875 6.984375 36.375 \nQ 6.984375 53.65625 15.1875 63.9375 \nQ 23.390625 74.21875 37.203125 74.21875 \nQ 40.921875 74.21875 44.703125 73.484375 \nQ 48.484375 72.75 52.59375 71.296875 \nz\n\" id=\"DejaVuSans-54\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-54\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"435.764721\" xlink:href=\"#m2e7f4990e4\" y=\"565.918125\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 1.8 -->\n      <g transform=\"translate(427.813159 580.516562)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 31.78125 34.625 \nQ 24.75 34.625 20.71875 30.859375 \nQ 16.703125 27.09375 16.703125 20.515625 \nQ 16.703125 13.921875 20.71875 10.15625 \nQ 24.75 6.390625 31.78125 6.390625 \nQ 38.8125 6.390625 42.859375 10.171875 \nQ 46.921875 13.96875 46.921875 20.515625 \nQ 46.921875 27.09375 42.890625 30.859375 \nQ 38.875 34.625 31.78125 34.625 \nz\nM 21.921875 38.8125 \nQ 15.578125 40.375 12.03125 44.71875 \nQ 8.5 49.078125 8.5 55.328125 \nQ 8.5 64.0625 14.71875 69.140625 \nQ 20.953125 74.21875 31.78125 74.21875 \nQ 42.671875 74.21875 48.875 69.140625 \nQ 55.078125 64.0625 55.078125 55.328125 \nQ 55.078125 49.078125 51.53125 44.71875 \nQ 48 40.375 41.703125 38.8125 \nQ 48.828125 37.15625 52.796875 32.3125 \nQ 56.78125 27.484375 56.78125 20.515625 \nQ 56.78125 9.90625 50.3125 4.234375 \nQ 43.84375 -1.421875 31.78125 -1.421875 \nQ 19.734375 -1.421875 13.25 4.234375 \nQ 6.78125 9.90625 6.78125 20.515625 \nQ 6.78125 27.484375 10.78125 32.3125 \nQ 14.796875 37.15625 21.921875 38.8125 \nz\nM 18.3125 54.390625 \nQ 18.3125 48.734375 21.84375 45.5625 \nQ 25.390625 42.390625 31.78125 42.390625 \nQ 38.140625 42.390625 41.71875 45.5625 \nQ 45.3125 48.734375 45.3125 54.390625 \nQ 45.3125 60.0625 41.71875 63.234375 \nQ 38.140625 66.40625 31.78125 66.40625 \nQ 25.390625 66.40625 21.84375 63.234375 \nQ 18.3125 60.0625 18.3125 54.390625 \nz\n\" id=\"DejaVuSans-56\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-56\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"527.996126\" xlink:href=\"#m2e7f4990e4\" y=\"565.918125\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 2.0 -->\n      <g transform=\"translate(520.044564 580.516562)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_7\">\n     <!-- Epoch -->\n     <g transform=\"translate(282.106676 594.194687)scale(0.1 -0.1)\">\n      <defs>\n       <path d=\"M 9.8125 72.90625 \nL 55.90625 72.90625 \nL 55.90625 64.59375 \nL 19.671875 64.59375 \nL 19.671875 43.015625 \nL 54.390625 43.015625 \nL 54.390625 34.71875 \nL 19.671875 34.71875 \nL 19.671875 8.296875 \nL 56.78125 8.296875 \nL 56.78125 0 \nL 9.8125 0 \nz\n\" id=\"DejaVuSans-69\"/>\n       <path d=\"M 18.109375 8.203125 \nL 18.109375 -20.796875 \nL 9.078125 -20.796875 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.390625 \nQ 20.953125 51.265625 25.265625 53.625 \nQ 29.59375 56 35.59375 56 \nQ 45.5625 56 51.78125 48.09375 \nQ 58.015625 40.1875 58.015625 27.296875 \nQ 58.015625 14.40625 51.78125 6.484375 \nQ 45.5625 -1.421875 35.59375 -1.421875 \nQ 29.59375 -1.421875 25.265625 0.953125 \nQ 20.953125 3.328125 18.109375 8.203125 \nz\nM 48.6875 27.296875 \nQ 48.6875 37.203125 44.609375 42.84375 \nQ 40.53125 48.484375 33.40625 48.484375 \nQ 26.265625 48.484375 22.1875 42.84375 \nQ 18.109375 37.203125 18.109375 27.296875 \nQ 18.109375 17.390625 22.1875 11.75 \nQ 26.265625 6.109375 33.40625 6.109375 \nQ 40.53125 6.109375 44.609375 11.75 \nQ 48.6875 17.390625 48.6875 27.296875 \nz\n\" id=\"DejaVuSans-112\"/>\n       <path d=\"M 30.609375 48.390625 \nQ 23.390625 48.390625 19.1875 42.75 \nQ 14.984375 37.109375 14.984375 27.296875 \nQ 14.984375 17.484375 19.15625 11.84375 \nQ 23.34375 6.203125 30.609375 6.203125 \nQ 37.796875 6.203125 41.984375 11.859375 \nQ 46.1875 17.53125 46.1875 27.296875 \nQ 46.1875 37.015625 41.984375 42.703125 \nQ 37.796875 48.390625 30.609375 48.390625 \nz\nM 30.609375 56 \nQ 42.328125 56 49.015625 48.375 \nQ 55.71875 40.765625 55.71875 27.296875 \nQ 55.71875 13.875 49.015625 6.21875 \nQ 42.328125 -1.421875 30.609375 -1.421875 \nQ 18.84375 -1.421875 12.171875 6.21875 \nQ 5.515625 13.875 5.515625 27.296875 \nQ 5.515625 40.765625 12.171875 48.375 \nQ 18.84375 56 30.609375 56 \nz\n\" id=\"DejaVuSans-111\"/>\n       <path d=\"M 48.78125 52.59375 \nL 48.78125 44.1875 \nQ 44.96875 46.296875 41.140625 47.34375 \nQ 37.3125 48.390625 33.40625 48.390625 \nQ 24.65625 48.390625 19.8125 42.84375 \nQ 14.984375 37.3125 14.984375 27.296875 \nQ 14.984375 17.28125 19.8125 11.734375 \nQ 24.65625 6.203125 33.40625 6.203125 \nQ 37.3125 6.203125 41.140625 7.25 \nQ 44.96875 8.296875 48.78125 10.40625 \nL 48.78125 2.09375 \nQ 45.015625 0.34375 40.984375 -0.53125 \nQ 36.96875 -1.421875 32.421875 -1.421875 \nQ 20.0625 -1.421875 12.78125 6.34375 \nQ 5.515625 14.109375 5.515625 27.296875 \nQ 5.515625 40.671875 12.859375 48.328125 \nQ 20.21875 56 33.015625 56 \nQ 37.15625 56 41.109375 55.140625 \nQ 45.0625 54.296875 48.78125 52.59375 \nz\n\" id=\"DejaVuSans-99\"/>\n       <path d=\"M 54.890625 33.015625 \nL 54.890625 0 \nL 45.90625 0 \nL 45.90625 32.71875 \nQ 45.90625 40.484375 42.875 44.328125 \nQ 39.84375 48.1875 33.796875 48.1875 \nQ 26.515625 48.1875 22.3125 43.546875 \nQ 18.109375 38.921875 18.109375 30.90625 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 75.984375 \nL 18.109375 75.984375 \nL 18.109375 46.1875 \nQ 21.34375 51.125 25.703125 53.5625 \nQ 30.078125 56 35.796875 56 \nQ 45.21875 56 50.046875 50.171875 \nQ 54.890625 44.34375 54.890625 33.015625 \nz\n\" id=\"DejaVuSans-104\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-69\"/>\n      <use x=\"63.183594\" xlink:href=\"#DejaVuSans-112\"/>\n      <use x=\"126.660156\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"187.841797\" xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"242.822266\" xlink:href=\"#DejaVuSans-104\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_7\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"mba5686b1be\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#mba5686b1be\" y=\"542.907246\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 0.0 -->\n      <g transform=\"translate(20.878125 546.706465)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#mba5686b1be\" y=\"472.545446\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 0.1 -->\n      <g transform=\"translate(20.878125 476.344665)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-49\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#mba5686b1be\" y=\"402.183646\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 0.2 -->\n      <g transform=\"translate(20.878125 405.982865)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#mba5686b1be\" y=\"331.821846\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 0.3 -->\n      <g transform=\"translate(20.878125 335.621064)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 40.578125 39.3125 \nQ 47.65625 37.796875 51.625 33 \nQ 55.609375 28.21875 55.609375 21.1875 \nQ 55.609375 10.40625 48.1875 4.484375 \nQ 40.765625 -1.421875 27.09375 -1.421875 \nQ 22.515625 -1.421875 17.65625 -0.515625 \nQ 12.796875 0.390625 7.625 2.203125 \nL 7.625 11.71875 \nQ 11.71875 9.328125 16.59375 8.109375 \nQ 21.484375 6.890625 26.8125 6.890625 \nQ 36.078125 6.890625 40.9375 10.546875 \nQ 45.796875 14.203125 45.796875 21.1875 \nQ 45.796875 27.640625 41.28125 31.265625 \nQ 36.765625 34.90625 28.71875 34.90625 \nL 20.21875 34.90625 \nL 20.21875 43.015625 \nL 29.109375 43.015625 \nQ 36.375 43.015625 40.234375 45.921875 \nQ 44.09375 48.828125 44.09375 54.296875 \nQ 44.09375 59.90625 40.109375 62.90625 \nQ 36.140625 65.921875 28.71875 65.921875 \nQ 24.65625 65.921875 20.015625 65.03125 \nQ 15.375 64.15625 9.8125 62.3125 \nL 9.8125 71.09375 \nQ 15.4375 72.65625 20.34375 73.4375 \nQ 25.25 74.21875 29.59375 74.21875 \nQ 40.828125 74.21875 47.359375 69.109375 \nQ 53.90625 64.015625 53.90625 55.328125 \nQ 53.90625 49.265625 50.4375 45.09375 \nQ 46.96875 40.921875 40.578125 39.3125 \nz\n\" id=\"DejaVuSans-51\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-51\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#mba5686b1be\" y=\"261.460045\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 0.4 -->\n      <g transform=\"translate(20.878125 265.259264)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#mba5686b1be\" y=\"191.098245\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 0.5 -->\n      <g transform=\"translate(20.878125 194.897464)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_13\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#mba5686b1be\" y=\"120.736445\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 0.6 -->\n      <g transform=\"translate(20.878125 124.535664)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-54\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_8\">\n     <g id=\"line2d_14\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#mba5686b1be\" y=\"50.374645\"/>\n      </g>\n     </g>\n     <g id=\"text_15\">\n      <!-- 0.7 -->\n      <g transform=\"translate(20.878125 54.173864)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 8.203125 72.90625 \nL 55.078125 72.90625 \nL 55.078125 68.703125 \nL 28.609375 0 \nL 18.3125 0 \nL 43.21875 64.59375 \nL 8.203125 64.59375 \nz\n\" id=\"DejaVuSans-55\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-55\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_16\">\n     <!-- Accuracy -->\n     <g transform=\"translate(14.798437 316.94625)rotate(-90)scale(0.1 -0.1)\">\n      <defs>\n       <path d=\"M 34.1875 63.1875 \nL 20.796875 26.90625 \nL 47.609375 26.90625 \nz\nM 28.609375 72.90625 \nL 39.796875 72.90625 \nL 67.578125 0 \nL 57.328125 0 \nL 50.6875 18.703125 \nL 17.828125 18.703125 \nL 11.1875 0 \nL 0.78125 0 \nz\n\" id=\"DejaVuSans-65\"/>\n       <path d=\"M 8.5 21.578125 \nL 8.5 54.6875 \nL 17.484375 54.6875 \nL 17.484375 21.921875 \nQ 17.484375 14.15625 20.5 10.265625 \nQ 23.53125 6.390625 29.59375 6.390625 \nQ 36.859375 6.390625 41.078125 11.03125 \nQ 45.3125 15.671875 45.3125 23.6875 \nL 45.3125 54.6875 \nL 54.296875 54.6875 \nL 54.296875 0 \nL 45.3125 0 \nL 45.3125 8.40625 \nQ 42.046875 3.421875 37.71875 1 \nQ 33.40625 -1.421875 27.6875 -1.421875 \nQ 18.265625 -1.421875 13.375 4.4375 \nQ 8.5 10.296875 8.5 21.578125 \nz\nM 31.109375 56 \nz\n\" id=\"DejaVuSans-117\"/>\n       <path d=\"M 41.109375 46.296875 \nQ 39.59375 47.171875 37.8125 47.578125 \nQ 36.03125 48 33.890625 48 \nQ 26.265625 48 22.1875 43.046875 \nQ 18.109375 38.09375 18.109375 28.8125 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 20.953125 51.171875 25.484375 53.578125 \nQ 30.03125 56 36.53125 56 \nQ 37.453125 56 38.578125 55.875 \nQ 39.703125 55.765625 41.0625 55.515625 \nz\n\" id=\"DejaVuSans-114\"/>\n       <path d=\"M 34.28125 27.484375 \nQ 23.390625 27.484375 19.1875 25 \nQ 14.984375 22.515625 14.984375 16.5 \nQ 14.984375 11.71875 18.140625 8.90625 \nQ 21.296875 6.109375 26.703125 6.109375 \nQ 34.1875 6.109375 38.703125 11.40625 \nQ 43.21875 16.703125 43.21875 25.484375 \nL 43.21875 27.484375 \nz\nM 52.203125 31.203125 \nL 52.203125 0 \nL 43.21875 0 \nL 43.21875 8.296875 \nQ 40.140625 3.328125 35.546875 0.953125 \nQ 30.953125 -1.421875 24.3125 -1.421875 \nQ 15.921875 -1.421875 10.953125 3.296875 \nQ 6 8.015625 6 15.921875 \nQ 6 25.140625 12.171875 29.828125 \nQ 18.359375 34.515625 30.609375 34.515625 \nL 43.21875 34.515625 \nL 43.21875 35.40625 \nQ 43.21875 41.609375 39.140625 45 \nQ 35.0625 48.390625 27.6875 48.390625 \nQ 23 48.390625 18.546875 47.265625 \nQ 14.109375 46.140625 10.015625 43.890625 \nL 10.015625 52.203125 \nQ 14.9375 54.109375 19.578125 55.046875 \nQ 24.21875 56 28.609375 56 \nQ 40.484375 56 46.34375 49.84375 \nQ 52.203125 43.703125 52.203125 31.203125 \nz\n\" id=\"DejaVuSans-97\"/>\n       <path d=\"M 32.171875 -5.078125 \nQ 28.375 -14.84375 24.75 -17.8125 \nQ 21.140625 -20.796875 15.09375 -20.796875 \nL 7.90625 -20.796875 \nL 7.90625 -13.28125 \nL 13.1875 -13.28125 \nQ 16.890625 -13.28125 18.9375 -11.515625 \nQ 21 -9.765625 23.484375 -3.21875 \nL 25.09375 0.875 \nL 2.984375 54.6875 \nL 12.5 54.6875 \nL 29.59375 11.921875 \nL 46.6875 54.6875 \nL 56.203125 54.6875 \nz\n\" id=\"DejaVuSans-121\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"66.658203\" xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"121.638672\" xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"176.619141\" xlink:href=\"#DejaVuSans-117\"/>\n      <use x=\"239.998047\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"281.111328\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"342.390625\" xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"397.371094\" xlink:href=\"#DejaVuSans-121\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_15\">\n    <path clip-path=\"url(#p51e1b8de34)\" d=\"M 66.839101 541.209034 \nL 527.996126 487.398411 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_16\">\n    <path clip-path=\"url(#p51e1b8de34)\" d=\"M 66.839101 484.828673 \nL 527.996126 47.027216 \n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 43.78125 565.918125 \nL 43.78125 22.318125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 551.053977 565.918125 \nL 551.053977 22.318125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 43.78125 565.918125 \nL 551.053977 565.918125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 43.78125 22.318125 \nL 551.053977 22.318125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"text_17\">\n    <!-- Training/Val Accuracy -->\n    <g transform=\"translate(233.441676 16.318125)scale(0.12 -0.12)\">\n     <defs>\n      <path d=\"M -0.296875 72.90625 \nL 61.375 72.90625 \nL 61.375 64.59375 \nL 35.5 64.59375 \nL 35.5 0 \nL 25.59375 0 \nL 25.59375 64.59375 \nL -0.296875 64.59375 \nz\n\" id=\"DejaVuSans-84\"/>\n      <path d=\"M 9.421875 54.6875 \nL 18.40625 54.6875 \nL 18.40625 0 \nL 9.421875 0 \nz\nM 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 64.59375 \nL 9.421875 64.59375 \nz\n\" id=\"DejaVuSans-105\"/>\n      <path d=\"M 54.890625 33.015625 \nL 54.890625 0 \nL 45.90625 0 \nL 45.90625 32.71875 \nQ 45.90625 40.484375 42.875 44.328125 \nQ 39.84375 48.1875 33.796875 48.1875 \nQ 26.515625 48.1875 22.3125 43.546875 \nQ 18.109375 38.921875 18.109375 30.90625 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 21.34375 51.125 25.703125 53.5625 \nQ 30.078125 56 35.796875 56 \nQ 45.21875 56 50.046875 50.171875 \nQ 54.890625 44.34375 54.890625 33.015625 \nz\n\" id=\"DejaVuSans-110\"/>\n      <path d=\"M 45.40625 27.984375 \nQ 45.40625 37.75 41.375 43.109375 \nQ 37.359375 48.484375 30.078125 48.484375 \nQ 22.859375 48.484375 18.828125 43.109375 \nQ 14.796875 37.75 14.796875 27.984375 \nQ 14.796875 18.265625 18.828125 12.890625 \nQ 22.859375 7.515625 30.078125 7.515625 \nQ 37.359375 7.515625 41.375 12.890625 \nQ 45.40625 18.265625 45.40625 27.984375 \nz\nM 54.390625 6.78125 \nQ 54.390625 -7.171875 48.1875 -13.984375 \nQ 42 -20.796875 29.203125 -20.796875 \nQ 24.46875 -20.796875 20.265625 -20.09375 \nQ 16.0625 -19.390625 12.109375 -17.921875 \nL 12.109375 -9.1875 \nQ 16.0625 -11.328125 19.921875 -12.34375 \nQ 23.78125 -13.375 27.78125 -13.375 \nQ 36.625 -13.375 41.015625 -8.765625 \nQ 45.40625 -4.15625 45.40625 5.171875 \nL 45.40625 9.625 \nQ 42.625 4.78125 38.28125 2.390625 \nQ 33.9375 0 27.875 0 \nQ 17.828125 0 11.671875 7.65625 \nQ 5.515625 15.328125 5.515625 27.984375 \nQ 5.515625 40.671875 11.671875 48.328125 \nQ 17.828125 56 27.875 56 \nQ 33.9375 56 38.28125 53.609375 \nQ 42.625 51.21875 45.40625 46.390625 \nL 45.40625 54.6875 \nL 54.390625 54.6875 \nz\n\" id=\"DejaVuSans-103\"/>\n      <path d=\"M 25.390625 72.90625 \nL 33.6875 72.90625 \nL 8.296875 -9.28125 \nL 0 -9.28125 \nz\n\" id=\"DejaVuSans-47\"/>\n      <path d=\"M 28.609375 0 \nL 0.78125 72.90625 \nL 11.078125 72.90625 \nL 34.1875 11.53125 \nL 57.328125 72.90625 \nL 67.578125 72.90625 \nL 39.796875 0 \nz\n\" id=\"DejaVuSans-86\"/>\n      <path d=\"M 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 0 \nL 9.421875 0 \nz\n\" id=\"DejaVuSans-108\"/>\n      <path id=\"DejaVuSans-32\"/>\n     </defs>\n     <use xlink:href=\"#DejaVuSans-84\"/>\n     <use x=\"46.333984\" xlink:href=\"#DejaVuSans-114\"/>\n     <use x=\"87.447266\" xlink:href=\"#DejaVuSans-97\"/>\n     <use x=\"148.726562\" xlink:href=\"#DejaVuSans-105\"/>\n     <use x=\"176.509766\" xlink:href=\"#DejaVuSans-110\"/>\n     <use x=\"239.888672\" xlink:href=\"#DejaVuSans-105\"/>\n     <use x=\"267.671875\" xlink:href=\"#DejaVuSans-110\"/>\n     <use x=\"331.050781\" xlink:href=\"#DejaVuSans-103\"/>\n     <use x=\"394.527344\" xlink:href=\"#DejaVuSans-47\"/>\n     <use x=\"428.21875\" xlink:href=\"#DejaVuSans-86\"/>\n     <use x=\"488.876953\" xlink:href=\"#DejaVuSans-97\"/>\n     <use x=\"550.15625\" xlink:href=\"#DejaVuSans-108\"/>\n     <use x=\"577.939453\" xlink:href=\"#DejaVuSans-32\"/>\n     <use x=\"609.726562\" xlink:href=\"#DejaVuSans-65\"/>\n     <use x=\"676.384766\" xlink:href=\"#DejaVuSans-99\"/>\n     <use x=\"731.365234\" xlink:href=\"#DejaVuSans-99\"/>\n     <use x=\"786.345703\" xlink:href=\"#DejaVuSans-117\"/>\n     <use x=\"849.724609\" xlink:href=\"#DejaVuSans-114\"/>\n     <use x=\"890.837891\" xlink:href=\"#DejaVuSans-97\"/>\n     <use x=\"952.117188\" xlink:href=\"#DejaVuSans-99\"/>\n     <use x=\"1007.097656\" xlink:href=\"#DejaVuSans-121\"/>\n    </g>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_7\">\n     <path d=\"M 50.78125 59.674375 \nL 106.76875 59.674375 \nQ 108.76875 59.674375 108.76875 57.674375 \nL 108.76875 29.318125 \nQ 108.76875 27.318125 106.76875 27.318125 \nL 50.78125 27.318125 \nQ 48.78125 27.318125 48.78125 29.318125 \nL 48.78125 57.674375 \nQ 48.78125 59.674375 50.78125 59.674375 \nz\n\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\n    </g>\n    <g id=\"line2d_17\">\n     <path d=\"M 52.78125 35.416562 \nL 72.78125 35.416562 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_18\"/>\n    <g id=\"text_18\">\n     <!-- Train -->\n     <g transform=\"translate(80.78125 38.916562)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-84\"/>\n      <use x=\"46.333984\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"87.447266\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"148.726562\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"176.509766\" xlink:href=\"#DejaVuSans-110\"/>\n     </g>\n    </g>\n    <g id=\"line2d_19\">\n     <path d=\"M 52.78125 50.094687 \nL 72.78125 50.094687 \n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_20\"/>\n    <g id=\"text_19\">\n     <!-- Val -->\n     <g transform=\"translate(80.78125 53.594687)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-86\"/>\n      <use x=\"60.658203\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"121.9375\" xlink:href=\"#DejaVuSans-108\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n  <g id=\"axes_2\">\n   <g id=\"patch_8\">\n    <path d=\"M 652.508523 565.918125 \nL 1159.78125 565.918125 \nL 1159.78125 22.318125 \nL 652.508523 22.318125 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_3\">\n    <g id=\"xtick_7\">\n     <g id=\"line2d_21\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"675.566374\" xlink:href=\"#m2e7f4990e4\" y=\"565.918125\"/>\n      </g>\n     </g>\n     <g id=\"text_20\">\n      <!-- 1.0 -->\n      <g transform=\"translate(667.614811 580.516562)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_8\">\n     <g id=\"line2d_22\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"767.797779\" xlink:href=\"#m2e7f4990e4\" y=\"565.918125\"/>\n      </g>\n     </g>\n     <g id=\"text_21\">\n      <!-- 1.2 -->\n      <g transform=\"translate(759.846216 580.516562)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_9\">\n     <g id=\"line2d_23\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"860.029184\" xlink:href=\"#m2e7f4990e4\" y=\"565.918125\"/>\n      </g>\n     </g>\n     <g id=\"text_22\">\n      <!-- 1.4 -->\n      <g transform=\"translate(852.077621 580.516562)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_10\">\n     <g id=\"line2d_24\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"952.260589\" xlink:href=\"#m2e7f4990e4\" y=\"565.918125\"/>\n      </g>\n     </g>\n     <g id=\"text_23\">\n      <!-- 1.6 -->\n      <g transform=\"translate(944.309026 580.516562)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-54\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_11\">\n     <g id=\"line2d_25\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"1044.491994\" xlink:href=\"#m2e7f4990e4\" y=\"565.918125\"/>\n      </g>\n     </g>\n     <g id=\"text_24\">\n      <!-- 1.8 -->\n      <g transform=\"translate(1036.540431 580.516562)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-56\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_12\">\n     <g id=\"line2d_26\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"1136.723399\" xlink:href=\"#m2e7f4990e4\" y=\"565.918125\"/>\n      </g>\n     </g>\n     <g id=\"text_25\">\n      <!-- 2.0 -->\n      <g transform=\"translate(1128.771836 580.516562)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_26\">\n     <!-- Epoch -->\n     <g transform=\"translate(890.833949 594.194687)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-69\"/>\n      <use x=\"63.183594\" xlink:href=\"#DejaVuSans-112\"/>\n      <use x=\"126.660156\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"187.841797\" xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"242.822266\" xlink:href=\"#DejaVuSans-104\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_4\">\n    <g id=\"ytick_9\">\n     <g id=\"line2d_27\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"652.508523\" xlink:href=\"#mba5686b1be\" y=\"498.077767\"/>\n      </g>\n     </g>\n     <g id=\"text_27\">\n      <!-- 2 -->\n      <g transform=\"translate(639.146023 501.876985)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_10\">\n     <g id=\"line2d_28\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"652.508523\" xlink:href=\"#mba5686b1be\" y=\"380.675865\"/>\n      </g>\n     </g>\n     <g id=\"text_28\">\n      <!-- 3 -->\n      <g transform=\"translate(639.146023 384.475083)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-51\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_11\">\n     <g id=\"line2d_29\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"652.508523\" xlink:href=\"#mba5686b1be\" y=\"263.273963\"/>\n      </g>\n     </g>\n     <g id=\"text_29\">\n      <!-- 4 -->\n      <g transform=\"translate(639.146023 267.073181)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_12\">\n     <g id=\"line2d_30\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"652.508523\" xlink:href=\"#mba5686b1be\" y=\"145.872061\"/>\n      </g>\n     </g>\n     <g id=\"text_30\">\n      <!-- 5 -->\n      <g transform=\"translate(639.146023 149.67128)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_13\">\n     <g id=\"line2d_31\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"652.508523\" xlink:href=\"#mba5686b1be\" y=\"28.470159\"/>\n      </g>\n     </g>\n     <g id=\"text_31\">\n      <!-- 6 -->\n      <g transform=\"translate(639.146023 32.269378)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-54\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_32\">\n     <!-- Loss -->\n     <g transform=\"translate(633.066335 305.085313)rotate(-90)scale(0.1 -0.1)\">\n      <defs>\n       <path d=\"M 9.8125 72.90625 \nL 19.671875 72.90625 \nL 19.671875 8.296875 \nL 55.171875 8.296875 \nL 55.171875 0 \nL 9.8125 0 \nz\n\" id=\"DejaVuSans-76\"/>\n       <path d=\"M 44.28125 53.078125 \nL 44.28125 44.578125 \nQ 40.484375 46.53125 36.375 47.5 \nQ 32.28125 48.484375 27.875 48.484375 \nQ 21.1875 48.484375 17.84375 46.4375 \nQ 14.5 44.390625 14.5 40.28125 \nQ 14.5 37.15625 16.890625 35.375 \nQ 19.28125 33.59375 26.515625 31.984375 \nL 29.59375 31.296875 \nQ 39.15625 29.25 43.1875 25.515625 \nQ 47.21875 21.78125 47.21875 15.09375 \nQ 47.21875 7.46875 41.1875 3.015625 \nQ 35.15625 -1.421875 24.609375 -1.421875 \nQ 20.21875 -1.421875 15.453125 -0.5625 \nQ 10.6875 0.296875 5.421875 2 \nL 5.421875 11.28125 \nQ 10.40625 8.6875 15.234375 7.390625 \nQ 20.0625 6.109375 24.8125 6.109375 \nQ 31.15625 6.109375 34.5625 8.28125 \nQ 37.984375 10.453125 37.984375 14.40625 \nQ 37.984375 18.0625 35.515625 20.015625 \nQ 33.0625 21.96875 24.703125 23.78125 \nL 21.578125 24.515625 \nQ 13.234375 26.265625 9.515625 29.90625 \nQ 5.8125 33.546875 5.8125 39.890625 \nQ 5.8125 47.609375 11.28125 51.796875 \nQ 16.75 56 26.8125 56 \nQ 31.78125 56 36.171875 55.265625 \nQ 40.578125 54.546875 44.28125 53.078125 \nz\n\" id=\"DejaVuSans-115\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-76\"/>\n      <use x=\"53.962891\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"115.144531\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"167.244141\" xlink:href=\"#DejaVuSans-115\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_32\">\n    <path clip-path=\"url(#pb2262cb11e)\" d=\"M 675.566374 47.027216 \nL 1136.723399 311.443881 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_33\">\n    <path clip-path=\"url(#pb2262cb11e)\" d=\"M 675.566374 145.087647 \nL 1136.723399 541.209034 \n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_9\">\n    <path d=\"M 652.508523 565.918125 \nL 652.508523 22.318125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_10\">\n    <path d=\"M 1159.78125 565.918125 \nL 1159.78125 22.318125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_11\">\n    <path d=\"M 652.508523 565.918125 \nL 1159.78125 565.918125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_12\">\n    <path d=\"M 652.508523 22.318125 \nL 1159.78125 22.318125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"text_33\">\n    <!-- Training/Val Loss -->\n    <g transform=\"translate(856.402074 16.318125)scale(0.12 -0.12)\">\n     <use xlink:href=\"#DejaVuSans-84\"/>\n     <use x=\"46.333984\" xlink:href=\"#DejaVuSans-114\"/>\n     <use x=\"87.447266\" xlink:href=\"#DejaVuSans-97\"/>\n     <use x=\"148.726562\" xlink:href=\"#DejaVuSans-105\"/>\n     <use x=\"176.509766\" xlink:href=\"#DejaVuSans-110\"/>\n     <use x=\"239.888672\" xlink:href=\"#DejaVuSans-105\"/>\n     <use x=\"267.671875\" xlink:href=\"#DejaVuSans-110\"/>\n     <use x=\"331.050781\" xlink:href=\"#DejaVuSans-103\"/>\n     <use x=\"394.527344\" xlink:href=\"#DejaVuSans-47\"/>\n     <use x=\"428.21875\" xlink:href=\"#DejaVuSans-86\"/>\n     <use x=\"488.876953\" xlink:href=\"#DejaVuSans-97\"/>\n     <use x=\"550.15625\" xlink:href=\"#DejaVuSans-108\"/>\n     <use x=\"577.939453\" xlink:href=\"#DejaVuSans-32\"/>\n     <use x=\"609.726562\" xlink:href=\"#DejaVuSans-76\"/>\n     <use x=\"663.689453\" xlink:href=\"#DejaVuSans-111\"/>\n     <use x=\"724.871094\" xlink:href=\"#DejaVuSans-115\"/>\n     <use x=\"776.970703\" xlink:href=\"#DejaVuSans-115\"/>\n    </g>\n   </g>\n   <g id=\"legend_2\">\n    <g id=\"patch_13\">\n     <path d=\"M 1096.79375 59.674375 \nL 1152.78125 59.674375 \nQ 1154.78125 59.674375 1154.78125 57.674375 \nL 1154.78125 29.318125 \nQ 1154.78125 27.318125 1152.78125 27.318125 \nL 1096.79375 27.318125 \nQ 1094.79375 27.318125 1094.79375 29.318125 \nL 1094.79375 57.674375 \nQ 1094.79375 59.674375 1096.79375 59.674375 \nz\n\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\n    </g>\n    <g id=\"line2d_34\">\n     <path d=\"M 1098.79375 35.416562 \nL 1118.79375 35.416562 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_35\"/>\n    <g id=\"text_34\">\n     <!-- Train -->\n     <g transform=\"translate(1126.79375 38.916562)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-84\"/>\n      <use x=\"46.333984\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"87.447266\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"148.726562\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"176.509766\" xlink:href=\"#DejaVuSans-110\"/>\n     </g>\n    </g>\n    <g id=\"line2d_36\">\n     <path d=\"M 1098.79375 50.094687 \nL 1118.79375 50.094687 \n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_37\"/>\n    <g id=\"text_35\">\n     <!-- Val -->\n     <g transform=\"translate(1126.79375 53.594687)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-86\"/>\n      <use x=\"60.658203\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"121.9375\" xlink:href=\"#DejaVuSans-108\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p51e1b8de34\">\n   <rect height=\"543.6\" width=\"507.272727\" x=\"43.78125\" y=\"22.318125\"/>\n  </clipPath>\n  <clipPath id=\"pb2262cb11e\">\n   <rect height=\"543.6\" width=\"507.272727\" x=\"652.508523\" y=\"22.318125\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "LR : 0.0002500000000000001, Batch Size : 128,  Epoch : 2\nTrain  : 0.07889058440923691, Train Loss : 3.589700698852539\nVal  : 0.7047574520111084, Val Loss : 1.6326186656951904\n  Val  : 0.7047574520111084\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from dataset import Dacon\n",
    "from model import *\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm, trange\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('use: ',device)\n",
    "\n",
    "checkpoint = torch.load('vit_base.pt')\n",
    "train_accuracy_list = checkpoint['train_accuracy']\n",
    "train_loss_list = checkpoint['train_loss']\n",
    "val_accuracy_list = checkpoint['val_accuracy']\n",
    "val_loss_list = checkpoint['val_loss']\n",
    "learning_rate = checkpoint['learning_rate']\n",
    "batch_size = checkpoint['batch_size']\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(20, 10))\n",
    "ax[0].set_title(\"Training/Val Accuracy\")\n",
    "ax[0].set_ylabel(\"Accuracy\")\n",
    "ax[0].set_xlabel(\"Epoch\")\n",
    "ax[0].plot(range(1, len(train_accuracy_list)+1), train_accuracy_list)\n",
    "ax[0].plot(range(1, len(val_accuracy_list)+1), val_accuracy_list)\n",
    "ax[0].legend(['Train', 'Val'])\n",
    "#ax[0].set_xlim(left=15)\n",
    "#ax[0].set_ylim(bottom=0.8)\n",
    "\n",
    "ax[1].set_title(\"Training/Val Loss\")\n",
    "ax[1].set_ylabel(\"Loss\")\n",
    "ax[1].set_xlabel(\"Epoch\")\n",
    "ax[1].plot(range(1, len(train_loss_list)+1), train_loss_list)\n",
    "ax[1].plot(range(1, len(val_loss_list)+1), val_loss_list)\n",
    "ax[1].legend(['Train', 'Val'])\n",
    "#ax[1].set_xlim(left=15)\n",
    "#ax[1].set_ylim(top=1.5)\n",
    "plt.show()\n",
    "\n",
    "print(f\"LR : {learning_rate}, Batch Size : {batch_size},  Epoch : {checkpoint['epoch']}\")\n",
    "print(f\"Train  : {train_accuracy_list[-1]}, Train Loss : {train_loss_list[-1]}\")\n",
    "print(f\"Val  : {val_accuracy_list[-1]}, Val Loss : {val_loss_list[-1]}\")\n",
    "print(f\"  Val  : {max(val_accuracy_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['cspresnext50',\n 'cspresnext50_iabn',\n 'ecaresnext26tn_32x4d',\n 'gluon_resnext50_32x4d',\n 'gluon_resnext101_32x4d',\n 'gluon_resnext101_64x4d',\n 'gluon_seresnext50_32x4d',\n 'gluon_seresnext101_32x4d',\n 'gluon_seresnext101_64x4d',\n 'ig_resnext101_32x8d',\n 'ig_resnext101_32x16d',\n 'ig_resnext101_32x32d',\n 'ig_resnext101_32x48d',\n 'legacy_seresnext26_32x4d',\n 'legacy_seresnext50_32x4d',\n 'legacy_seresnext101_32x4d',\n 'resnext50_32x4d',\n 'resnext50d_32x4d',\n 'resnext101_32x4d',\n 'resnext101_32x8d',\n 'resnext101_64x4d',\n 'seresnext26_32x4d',\n 'seresnext26d_32x4d',\n 'seresnext26t_32x4d',\n 'seresnext26tn_32x4d',\n 'seresnext50_32x4d',\n 'seresnext101_32x4d',\n 'seresnext101_32x8d',\n 'skresnext50_32x4d',\n 'ssl_resnext50_32x4d',\n 'ssl_resnext101_32x4d',\n 'ssl_resnext101_32x8d',\n 'ssl_resnext101_32x16d',\n 'swsl_resnext50_32x4d',\n 'swsl_resnext101_32x4d',\n 'swsl_resnext101_32x8d',\n 'swsl_resnext101_32x16d',\n 'tv_resnext50_32x4d']\n"
     ]
    }
   ],
   "source": [
    "import timm\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from pprint import pprint\n",
    "from torchsummary import summary\n",
    "\n",
    "name = timm.list_models(\"*resnext*\")\n",
    "pprint(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/skresnext50_ra-f40e40bf.pth\" to /home/jiuk/.cache/torch/hub/checkpoints/skresnext50_ra-f40e40bf.pth\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "              ReLU-3         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
      "            Conv2d-5          [-1, 128, 56, 56]           8,192\n",
      "              ReLU-6          [-1, 128, 56, 56]               0\n",
      "    BatchNormAct2d-7          [-1, 128, 56, 56]             256\n",
      "         ConvBnAct-8          [-1, 128, 56, 56]               0\n",
      "            Conv2d-9          [-1, 128, 56, 56]           4,608\n",
      "             ReLU-10          [-1, 128, 56, 56]               0\n",
      "   BatchNormAct2d-11          [-1, 128, 56, 56]             256\n",
      "        ConvBnAct-12          [-1, 128, 56, 56]               0\n",
      "           Conv2d-13          [-1, 128, 56, 56]           4,608\n",
      "             ReLU-14          [-1, 128, 56, 56]               0\n",
      "   BatchNormAct2d-15          [-1, 128, 56, 56]             256\n",
      "        ConvBnAct-16          [-1, 128, 56, 56]               0\n",
      "           Conv2d-17             [-1, 32, 1, 1]           4,096\n",
      "      BatchNorm2d-18             [-1, 32, 1, 1]              64\n",
      "             ReLU-19             [-1, 32, 1, 1]               0\n",
      "           Conv2d-20            [-1, 256, 1, 1]           8,192\n",
      "SelectiveKernelAttn-21         [-1, 2, 128, 1, 1]               0\n",
      "SelectiveKernelConv-22          [-1, 128, 56, 56]               0\n",
      "           Conv2d-23          [-1, 256, 56, 56]          32,768\n",
      "   BatchNormAct2d-24          [-1, 256, 56, 56]             512\n",
      "        ConvBnAct-25          [-1, 256, 56, 56]               0\n",
      "           Conv2d-26          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-27          [-1, 256, 56, 56]             512\n",
      "             ReLU-28          [-1, 256, 56, 56]               0\n",
      "SelectiveKernelBottleneck-29          [-1, 256, 56, 56]               0\n",
      "           Conv2d-30          [-1, 128, 56, 56]          32,768\n",
      "             ReLU-31          [-1, 128, 56, 56]               0\n",
      "   BatchNormAct2d-32          [-1, 128, 56, 56]             256\n",
      "        ConvBnAct-33          [-1, 128, 56, 56]               0\n",
      "           Conv2d-34          [-1, 128, 56, 56]           4,608\n",
      "             ReLU-35          [-1, 128, 56, 56]               0\n",
      "   BatchNormAct2d-36          [-1, 128, 56, 56]             256\n",
      "        ConvBnAct-37          [-1, 128, 56, 56]               0\n",
      "           Conv2d-38          [-1, 128, 56, 56]           4,608\n",
      "             ReLU-39          [-1, 128, 56, 56]               0\n",
      "   BatchNormAct2d-40          [-1, 128, 56, 56]             256\n",
      "        ConvBnAct-41          [-1, 128, 56, 56]               0\n",
      "           Conv2d-42             [-1, 32, 1, 1]           4,096\n",
      "      BatchNorm2d-43             [-1, 32, 1, 1]              64\n",
      "             ReLU-44             [-1, 32, 1, 1]               0\n",
      "           Conv2d-45            [-1, 256, 1, 1]           8,192\n",
      "SelectiveKernelAttn-46         [-1, 2, 128, 1, 1]               0\n",
      "SelectiveKernelConv-47          [-1, 128, 56, 56]               0\n",
      "           Conv2d-48          [-1, 256, 56, 56]          32,768\n",
      "   BatchNormAct2d-49          [-1, 256, 56, 56]             512\n",
      "        ConvBnAct-50          [-1, 256, 56, 56]               0\n",
      "             ReLU-51          [-1, 256, 56, 56]               0\n",
      "SelectiveKernelBottleneck-52          [-1, 256, 56, 56]               0\n",
      "           Conv2d-53          [-1, 128, 56, 56]          32,768\n",
      "             ReLU-54          [-1, 128, 56, 56]               0\n",
      "   BatchNormAct2d-55          [-1, 128, 56, 56]             256\n",
      "        ConvBnAct-56          [-1, 128, 56, 56]               0\n",
      "           Conv2d-57          [-1, 128, 56, 56]           4,608\n",
      "             ReLU-58          [-1, 128, 56, 56]               0\n",
      "   BatchNormAct2d-59          [-1, 128, 56, 56]             256\n",
      "        ConvBnAct-60          [-1, 128, 56, 56]               0\n",
      "           Conv2d-61          [-1, 128, 56, 56]           4,608\n",
      "             ReLU-62          [-1, 128, 56, 56]               0\n",
      "   BatchNormAct2d-63          [-1, 128, 56, 56]             256\n",
      "        ConvBnAct-64          [-1, 128, 56, 56]               0\n",
      "           Conv2d-65             [-1, 32, 1, 1]           4,096\n",
      "      BatchNorm2d-66             [-1, 32, 1, 1]              64\n",
      "             ReLU-67             [-1, 32, 1, 1]               0\n",
      "           Conv2d-68            [-1, 256, 1, 1]           8,192\n",
      "SelectiveKernelAttn-69         [-1, 2, 128, 1, 1]               0\n",
      "SelectiveKernelConv-70          [-1, 128, 56, 56]               0\n",
      "           Conv2d-71          [-1, 256, 56, 56]          32,768\n",
      "   BatchNormAct2d-72          [-1, 256, 56, 56]             512\n",
      "        ConvBnAct-73          [-1, 256, 56, 56]               0\n",
      "             ReLU-74          [-1, 256, 56, 56]               0\n",
      "SelectiveKernelBottleneck-75          [-1, 256, 56, 56]               0\n",
      "           Conv2d-76          [-1, 256, 56, 56]          65,536\n",
      "             ReLU-77          [-1, 256, 56, 56]               0\n",
      "   BatchNormAct2d-78          [-1, 256, 56, 56]             512\n",
      "        ConvBnAct-79          [-1, 256, 56, 56]               0\n",
      "           Conv2d-80          [-1, 256, 28, 28]          18,432\n",
      "             ReLU-81          [-1, 256, 28, 28]               0\n",
      "   BatchNormAct2d-82          [-1, 256, 28, 28]             512\n",
      "        ConvBnAct-83          [-1, 256, 28, 28]               0\n",
      "           Conv2d-84          [-1, 256, 28, 28]          18,432\n",
      "             ReLU-85          [-1, 256, 28, 28]               0\n",
      "   BatchNormAct2d-86          [-1, 256, 28, 28]             512\n",
      "        ConvBnAct-87          [-1, 256, 28, 28]               0\n",
      "           Conv2d-88             [-1, 32, 1, 1]           8,192\n",
      "      BatchNorm2d-89             [-1, 32, 1, 1]              64\n",
      "             ReLU-90             [-1, 32, 1, 1]               0\n",
      "           Conv2d-91            [-1, 512, 1, 1]          16,384\n",
      "SelectiveKernelAttn-92         [-1, 2, 256, 1, 1]               0\n",
      "SelectiveKernelConv-93          [-1, 256, 28, 28]               0\n",
      "           Conv2d-94          [-1, 512, 28, 28]         131,072\n",
      "   BatchNormAct2d-95          [-1, 512, 28, 28]           1,024\n",
      "        ConvBnAct-96          [-1, 512, 28, 28]               0\n",
      "           Conv2d-97          [-1, 512, 28, 28]         131,072\n",
      "      BatchNorm2d-98          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-99          [-1, 512, 28, 28]               0\n",
      "SelectiveKernelBottleneck-100          [-1, 512, 28, 28]               0\n",
      "          Conv2d-101          [-1, 256, 28, 28]         131,072\n",
      "            ReLU-102          [-1, 256, 28, 28]               0\n",
      "  BatchNormAct2d-103          [-1, 256, 28, 28]             512\n",
      "       ConvBnAct-104          [-1, 256, 28, 28]               0\n",
      "          Conv2d-105          [-1, 256, 28, 28]          18,432\n",
      "            ReLU-106          [-1, 256, 28, 28]               0\n",
      "  BatchNormAct2d-107          [-1, 256, 28, 28]             512\n",
      "       ConvBnAct-108          [-1, 256, 28, 28]               0\n",
      "          Conv2d-109          [-1, 256, 28, 28]          18,432\n",
      "            ReLU-110          [-1, 256, 28, 28]               0\n",
      "  BatchNormAct2d-111          [-1, 256, 28, 28]             512\n",
      "       ConvBnAct-112          [-1, 256, 28, 28]               0\n",
      "          Conv2d-113             [-1, 32, 1, 1]           8,192\n",
      "     BatchNorm2d-114             [-1, 32, 1, 1]              64\n",
      "            ReLU-115             [-1, 32, 1, 1]               0\n",
      "          Conv2d-116            [-1, 512, 1, 1]          16,384\n",
      "SelectiveKernelAttn-117         [-1, 2, 256, 1, 1]               0\n",
      "SelectiveKernelConv-118          [-1, 256, 28, 28]               0\n",
      "          Conv2d-119          [-1, 512, 28, 28]         131,072\n",
      "  BatchNormAct2d-120          [-1, 512, 28, 28]           1,024\n",
      "       ConvBnAct-121          [-1, 512, 28, 28]               0\n",
      "            ReLU-122          [-1, 512, 28, 28]               0\n",
      "SelectiveKernelBottleneck-123          [-1, 512, 28, 28]               0\n",
      "          Conv2d-124          [-1, 256, 28, 28]         131,072\n",
      "            ReLU-125          [-1, 256, 28, 28]               0\n",
      "  BatchNormAct2d-126          [-1, 256, 28, 28]             512\n",
      "       ConvBnAct-127          [-1, 256, 28, 28]               0\n",
      "          Conv2d-128          [-1, 256, 28, 28]          18,432\n",
      "            ReLU-129          [-1, 256, 28, 28]               0\n",
      "  BatchNormAct2d-130          [-1, 256, 28, 28]             512\n",
      "       ConvBnAct-131          [-1, 256, 28, 28]               0\n",
      "          Conv2d-132          [-1, 256, 28, 28]          18,432\n",
      "            ReLU-133          [-1, 256, 28, 28]               0\n",
      "  BatchNormAct2d-134          [-1, 256, 28, 28]             512\n",
      "       ConvBnAct-135          [-1, 256, 28, 28]               0\n",
      "          Conv2d-136             [-1, 32, 1, 1]           8,192\n",
      "     BatchNorm2d-137             [-1, 32, 1, 1]              64\n",
      "            ReLU-138             [-1, 32, 1, 1]               0\n",
      "          Conv2d-139            [-1, 512, 1, 1]          16,384\n",
      "SelectiveKernelAttn-140         [-1, 2, 256, 1, 1]               0\n",
      "SelectiveKernelConv-141          [-1, 256, 28, 28]               0\n",
      "          Conv2d-142          [-1, 512, 28, 28]         131,072\n",
      "  BatchNormAct2d-143          [-1, 512, 28, 28]           1,024\n",
      "       ConvBnAct-144          [-1, 512, 28, 28]               0\n",
      "            ReLU-145          [-1, 512, 28, 28]               0\n",
      "SelectiveKernelBottleneck-146          [-1, 512, 28, 28]               0\n",
      "          Conv2d-147          [-1, 256, 28, 28]         131,072\n",
      "            ReLU-148          [-1, 256, 28, 28]               0\n",
      "  BatchNormAct2d-149          [-1, 256, 28, 28]             512\n",
      "       ConvBnAct-150          [-1, 256, 28, 28]               0\n",
      "          Conv2d-151          [-1, 256, 28, 28]          18,432\n",
      "            ReLU-152          [-1, 256, 28, 28]               0\n",
      "  BatchNormAct2d-153          [-1, 256, 28, 28]             512\n",
      "       ConvBnAct-154          [-1, 256, 28, 28]               0\n",
      "          Conv2d-155          [-1, 256, 28, 28]          18,432\n",
      "            ReLU-156          [-1, 256, 28, 28]               0\n",
      "  BatchNormAct2d-157          [-1, 256, 28, 28]             512\n",
      "       ConvBnAct-158          [-1, 256, 28, 28]               0\n",
      "          Conv2d-159             [-1, 32, 1, 1]           8,192\n",
      "     BatchNorm2d-160             [-1, 32, 1, 1]              64\n",
      "            ReLU-161             [-1, 32, 1, 1]               0\n",
      "          Conv2d-162            [-1, 512, 1, 1]          16,384\n",
      "SelectiveKernelAttn-163         [-1, 2, 256, 1, 1]               0\n",
      "SelectiveKernelConv-164          [-1, 256, 28, 28]               0\n",
      "          Conv2d-165          [-1, 512, 28, 28]         131,072\n",
      "  BatchNormAct2d-166          [-1, 512, 28, 28]           1,024\n",
      "       ConvBnAct-167          [-1, 512, 28, 28]               0\n",
      "            ReLU-168          [-1, 512, 28, 28]               0\n",
      "SelectiveKernelBottleneck-169          [-1, 512, 28, 28]               0\n",
      "          Conv2d-170          [-1, 512, 28, 28]         262,144\n",
      "            ReLU-171          [-1, 512, 28, 28]               0\n",
      "  BatchNormAct2d-172          [-1, 512, 28, 28]           1,024\n",
      "       ConvBnAct-173          [-1, 512, 28, 28]               0\n",
      "          Conv2d-174          [-1, 512, 14, 14]          73,728\n",
      "            ReLU-175          [-1, 512, 14, 14]               0\n",
      "  BatchNormAct2d-176          [-1, 512, 14, 14]           1,024\n",
      "       ConvBnAct-177          [-1, 512, 14, 14]               0\n",
      "          Conv2d-178          [-1, 512, 14, 14]          73,728\n",
      "            ReLU-179          [-1, 512, 14, 14]               0\n",
      "  BatchNormAct2d-180          [-1, 512, 14, 14]           1,024\n",
      "       ConvBnAct-181          [-1, 512, 14, 14]               0\n",
      "          Conv2d-182             [-1, 32, 1, 1]          16,384\n",
      "     BatchNorm2d-183             [-1, 32, 1, 1]              64\n",
      "            ReLU-184             [-1, 32, 1, 1]               0\n",
      "          Conv2d-185           [-1, 1024, 1, 1]          32,768\n",
      "SelectiveKernelAttn-186         [-1, 2, 512, 1, 1]               0\n",
      "SelectiveKernelConv-187          [-1, 512, 14, 14]               0\n",
      "          Conv2d-188         [-1, 1024, 14, 14]         524,288\n",
      "  BatchNormAct2d-189         [-1, 1024, 14, 14]           2,048\n",
      "       ConvBnAct-190         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-191         [-1, 1024, 14, 14]         524,288\n",
      "     BatchNorm2d-192         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-193         [-1, 1024, 14, 14]               0\n",
      "SelectiveKernelBottleneck-194         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-195          [-1, 512, 14, 14]         524,288\n",
      "            ReLU-196          [-1, 512, 14, 14]               0\n",
      "  BatchNormAct2d-197          [-1, 512, 14, 14]           1,024\n",
      "       ConvBnAct-198          [-1, 512, 14, 14]               0\n",
      "          Conv2d-199          [-1, 512, 14, 14]          73,728\n",
      "            ReLU-200          [-1, 512, 14, 14]               0\n",
      "  BatchNormAct2d-201          [-1, 512, 14, 14]           1,024\n",
      "       ConvBnAct-202          [-1, 512, 14, 14]               0\n",
      "          Conv2d-203          [-1, 512, 14, 14]          73,728\n",
      "            ReLU-204          [-1, 512, 14, 14]               0\n",
      "  BatchNormAct2d-205          [-1, 512, 14, 14]           1,024\n",
      "       ConvBnAct-206          [-1, 512, 14, 14]               0\n",
      "          Conv2d-207             [-1, 32, 1, 1]          16,384\n",
      "     BatchNorm2d-208             [-1, 32, 1, 1]              64\n",
      "            ReLU-209             [-1, 32, 1, 1]               0\n",
      "          Conv2d-210           [-1, 1024, 1, 1]          32,768\n",
      "SelectiveKernelAttn-211         [-1, 2, 512, 1, 1]               0\n",
      "SelectiveKernelConv-212          [-1, 512, 14, 14]               0\n",
      "          Conv2d-213         [-1, 1024, 14, 14]         524,288\n",
      "  BatchNormAct2d-214         [-1, 1024, 14, 14]           2,048\n",
      "       ConvBnAct-215         [-1, 1024, 14, 14]               0\n",
      "            ReLU-216         [-1, 1024, 14, 14]               0\n",
      "SelectiveKernelBottleneck-217         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-218          [-1, 512, 14, 14]         524,288\n",
      "            ReLU-219          [-1, 512, 14, 14]               0\n",
      "  BatchNormAct2d-220          [-1, 512, 14, 14]           1,024\n",
      "       ConvBnAct-221          [-1, 512, 14, 14]               0\n",
      "          Conv2d-222          [-1, 512, 14, 14]          73,728\n",
      "            ReLU-223          [-1, 512, 14, 14]               0\n",
      "  BatchNormAct2d-224          [-1, 512, 14, 14]           1,024\n",
      "       ConvBnAct-225          [-1, 512, 14, 14]               0\n",
      "          Conv2d-226          [-1, 512, 14, 14]          73,728\n",
      "            ReLU-227          [-1, 512, 14, 14]               0\n",
      "  BatchNormAct2d-228          [-1, 512, 14, 14]           1,024\n",
      "       ConvBnAct-229          [-1, 512, 14, 14]               0\n",
      "          Conv2d-230             [-1, 32, 1, 1]          16,384\n",
      "     BatchNorm2d-231             [-1, 32, 1, 1]              64\n",
      "            ReLU-232             [-1, 32, 1, 1]               0\n",
      "          Conv2d-233           [-1, 1024, 1, 1]          32,768\n",
      "SelectiveKernelAttn-234         [-1, 2, 512, 1, 1]               0\n",
      "SelectiveKernelConv-235          [-1, 512, 14, 14]               0\n",
      "          Conv2d-236         [-1, 1024, 14, 14]         524,288\n",
      "  BatchNormAct2d-237         [-1, 1024, 14, 14]           2,048\n",
      "       ConvBnAct-238         [-1, 1024, 14, 14]               0\n",
      "            ReLU-239         [-1, 1024, 14, 14]               0\n",
      "SelectiveKernelBottleneck-240         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-241          [-1, 512, 14, 14]         524,288\n",
      "            ReLU-242          [-1, 512, 14, 14]               0\n",
      "  BatchNormAct2d-243          [-1, 512, 14, 14]           1,024\n",
      "       ConvBnAct-244          [-1, 512, 14, 14]               0\n",
      "          Conv2d-245          [-1, 512, 14, 14]          73,728\n",
      "            ReLU-246          [-1, 512, 14, 14]               0\n",
      "  BatchNormAct2d-247          [-1, 512, 14, 14]           1,024\n",
      "       ConvBnAct-248          [-1, 512, 14, 14]               0\n",
      "          Conv2d-249          [-1, 512, 14, 14]          73,728\n",
      "            ReLU-250          [-1, 512, 14, 14]               0\n",
      "  BatchNormAct2d-251          [-1, 512, 14, 14]           1,024\n",
      "       ConvBnAct-252          [-1, 512, 14, 14]               0\n",
      "          Conv2d-253             [-1, 32, 1, 1]          16,384\n",
      "     BatchNorm2d-254             [-1, 32, 1, 1]              64\n",
      "            ReLU-255             [-1, 32, 1, 1]               0\n",
      "          Conv2d-256           [-1, 1024, 1, 1]          32,768\n",
      "SelectiveKernelAttn-257         [-1, 2, 512, 1, 1]               0\n",
      "SelectiveKernelConv-258          [-1, 512, 14, 14]               0\n",
      "          Conv2d-259         [-1, 1024, 14, 14]         524,288\n",
      "  BatchNormAct2d-260         [-1, 1024, 14, 14]           2,048\n",
      "       ConvBnAct-261         [-1, 1024, 14, 14]               0\n",
      "            ReLU-262         [-1, 1024, 14, 14]               0\n",
      "SelectiveKernelBottleneck-263         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-264          [-1, 512, 14, 14]         524,288\n",
      "            ReLU-265          [-1, 512, 14, 14]               0\n",
      "  BatchNormAct2d-266          [-1, 512, 14, 14]           1,024\n",
      "       ConvBnAct-267          [-1, 512, 14, 14]               0\n",
      "          Conv2d-268          [-1, 512, 14, 14]          73,728\n",
      "            ReLU-269          [-1, 512, 14, 14]               0\n",
      "  BatchNormAct2d-270          [-1, 512, 14, 14]           1,024\n",
      "       ConvBnAct-271          [-1, 512, 14, 14]               0\n",
      "          Conv2d-272          [-1, 512, 14, 14]          73,728\n",
      "            ReLU-273          [-1, 512, 14, 14]               0\n",
      "  BatchNormAct2d-274          [-1, 512, 14, 14]           1,024\n",
      "       ConvBnAct-275          [-1, 512, 14, 14]               0\n",
      "          Conv2d-276             [-1, 32, 1, 1]          16,384\n",
      "     BatchNorm2d-277             [-1, 32, 1, 1]              64\n",
      "            ReLU-278             [-1, 32, 1, 1]               0\n",
      "          Conv2d-279           [-1, 1024, 1, 1]          32,768\n",
      "SelectiveKernelAttn-280         [-1, 2, 512, 1, 1]               0\n",
      "SelectiveKernelConv-281          [-1, 512, 14, 14]               0\n",
      "          Conv2d-282         [-1, 1024, 14, 14]         524,288\n",
      "  BatchNormAct2d-283         [-1, 1024, 14, 14]           2,048\n",
      "       ConvBnAct-284         [-1, 1024, 14, 14]               0\n",
      "            ReLU-285         [-1, 1024, 14, 14]               0\n",
      "SelectiveKernelBottleneck-286         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-287          [-1, 512, 14, 14]         524,288\n",
      "            ReLU-288          [-1, 512, 14, 14]               0\n",
      "  BatchNormAct2d-289          [-1, 512, 14, 14]           1,024\n",
      "       ConvBnAct-290          [-1, 512, 14, 14]               0\n",
      "          Conv2d-291          [-1, 512, 14, 14]          73,728\n",
      "            ReLU-292          [-1, 512, 14, 14]               0\n",
      "  BatchNormAct2d-293          [-1, 512, 14, 14]           1,024\n",
      "       ConvBnAct-294          [-1, 512, 14, 14]               0\n",
      "          Conv2d-295          [-1, 512, 14, 14]          73,728\n",
      "            ReLU-296          [-1, 512, 14, 14]               0\n",
      "  BatchNormAct2d-297          [-1, 512, 14, 14]           1,024\n",
      "       ConvBnAct-298          [-1, 512, 14, 14]               0\n",
      "          Conv2d-299             [-1, 32, 1, 1]          16,384\n",
      "     BatchNorm2d-300             [-1, 32, 1, 1]              64\n",
      "            ReLU-301             [-1, 32, 1, 1]               0\n",
      "          Conv2d-302           [-1, 1024, 1, 1]          32,768\n",
      "SelectiveKernelAttn-303         [-1, 2, 512, 1, 1]               0\n",
      "SelectiveKernelConv-304          [-1, 512, 14, 14]               0\n",
      "          Conv2d-305         [-1, 1024, 14, 14]         524,288\n",
      "  BatchNormAct2d-306         [-1, 1024, 14, 14]           2,048\n",
      "       ConvBnAct-307         [-1, 1024, 14, 14]               0\n",
      "            ReLU-308         [-1, 1024, 14, 14]               0\n",
      "SelectiveKernelBottleneck-309         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-310         [-1, 1024, 14, 14]       1,048,576\n",
      "            ReLU-311         [-1, 1024, 14, 14]               0\n",
      "  BatchNormAct2d-312         [-1, 1024, 14, 14]           2,048\n",
      "       ConvBnAct-313         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-314           [-1, 1024, 7, 7]         294,912\n",
      "            ReLU-315           [-1, 1024, 7, 7]               0\n",
      "  BatchNormAct2d-316           [-1, 1024, 7, 7]           2,048\n",
      "       ConvBnAct-317           [-1, 1024, 7, 7]               0\n",
      "          Conv2d-318           [-1, 1024, 7, 7]         294,912\n",
      "            ReLU-319           [-1, 1024, 7, 7]               0\n",
      "  BatchNormAct2d-320           [-1, 1024, 7, 7]           2,048\n",
      "       ConvBnAct-321           [-1, 1024, 7, 7]               0\n",
      "          Conv2d-322             [-1, 64, 1, 1]          65,536\n",
      "     BatchNorm2d-323             [-1, 64, 1, 1]             128\n",
      "            ReLU-324             [-1, 64, 1, 1]               0\n",
      "          Conv2d-325           [-1, 2048, 1, 1]         131,072\n",
      "SelectiveKernelAttn-326        [-1, 2, 1024, 1, 1]               0\n",
      "SelectiveKernelConv-327           [-1, 1024, 7, 7]               0\n",
      "          Conv2d-328           [-1, 2048, 7, 7]       2,097,152\n",
      "  BatchNormAct2d-329           [-1, 2048, 7, 7]           4,096\n",
      "       ConvBnAct-330           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-331           [-1, 2048, 7, 7]       2,097,152\n",
      "     BatchNorm2d-332           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-333           [-1, 2048, 7, 7]               0\n",
      "SelectiveKernelBottleneck-334           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-335           [-1, 1024, 7, 7]       2,097,152\n",
      "            ReLU-336           [-1, 1024, 7, 7]               0\n",
      "  BatchNormAct2d-337           [-1, 1024, 7, 7]           2,048\n",
      "       ConvBnAct-338           [-1, 1024, 7, 7]               0\n",
      "          Conv2d-339           [-1, 1024, 7, 7]         294,912\n",
      "            ReLU-340           [-1, 1024, 7, 7]               0\n",
      "  BatchNormAct2d-341           [-1, 1024, 7, 7]           2,048\n",
      "       ConvBnAct-342           [-1, 1024, 7, 7]               0\n",
      "          Conv2d-343           [-1, 1024, 7, 7]         294,912\n",
      "            ReLU-344           [-1, 1024, 7, 7]               0\n",
      "  BatchNormAct2d-345           [-1, 1024, 7, 7]           2,048\n",
      "       ConvBnAct-346           [-1, 1024, 7, 7]               0\n",
      "          Conv2d-347             [-1, 64, 1, 1]          65,536\n",
      "     BatchNorm2d-348             [-1, 64, 1, 1]             128\n",
      "            ReLU-349             [-1, 64, 1, 1]               0\n",
      "          Conv2d-350           [-1, 2048, 1, 1]         131,072\n",
      "SelectiveKernelAttn-351        [-1, 2, 1024, 1, 1]               0\n",
      "SelectiveKernelConv-352           [-1, 1024, 7, 7]               0\n",
      "          Conv2d-353           [-1, 2048, 7, 7]       2,097,152\n",
      "  BatchNormAct2d-354           [-1, 2048, 7, 7]           4,096\n",
      "       ConvBnAct-355           [-1, 2048, 7, 7]               0\n",
      "            ReLU-356           [-1, 2048, 7, 7]               0\n",
      "SelectiveKernelBottleneck-357           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-358           [-1, 1024, 7, 7]       2,097,152\n",
      "            ReLU-359           [-1, 1024, 7, 7]               0\n",
      "  BatchNormAct2d-360           [-1, 1024, 7, 7]           2,048\n",
      "       ConvBnAct-361           [-1, 1024, 7, 7]               0\n",
      "          Conv2d-362           [-1, 1024, 7, 7]         294,912\n",
      "            ReLU-363           [-1, 1024, 7, 7]               0\n",
      "  BatchNormAct2d-364           [-1, 1024, 7, 7]           2,048\n",
      "       ConvBnAct-365           [-1, 1024, 7, 7]               0\n",
      "          Conv2d-366           [-1, 1024, 7, 7]         294,912\n",
      "            ReLU-367           [-1, 1024, 7, 7]               0\n",
      "  BatchNormAct2d-368           [-1, 1024, 7, 7]           2,048\n",
      "       ConvBnAct-369           [-1, 1024, 7, 7]               0\n",
      "          Conv2d-370             [-1, 64, 1, 1]          65,536\n",
      "     BatchNorm2d-371             [-1, 64, 1, 1]             128\n",
      "            ReLU-372             [-1, 64, 1, 1]               0\n",
      "          Conv2d-373           [-1, 2048, 1, 1]         131,072\n",
      "SelectiveKernelAttn-374        [-1, 2, 1024, 1, 1]               0\n",
      "SelectiveKernelConv-375           [-1, 1024, 7, 7]               0\n",
      "          Conv2d-376           [-1, 2048, 7, 7]       2,097,152\n",
      "  BatchNormAct2d-377           [-1, 2048, 7, 7]           4,096\n",
      "       ConvBnAct-378           [-1, 2048, 7, 7]               0\n",
      "            ReLU-379           [-1, 2048, 7, 7]               0\n",
      "SelectiveKernelBottleneck-380           [-1, 2048, 7, 7]               0\n",
      "AdaptiveAvgPool2d-381           [-1, 2048, 1, 1]               0\n",
      "SelectAdaptivePool2d-382                 [-1, 2048]               0\n",
      "          Linear-383                 [-1, 1049]       2,149,401\n",
      "================================================================\n",
      "Total params: 27,580,185\n",
      "Trainable params: 27,580,185\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 559.57\n",
      "Params size (MB): 105.21\n",
      "Estimated Total Size (MB): 665.36\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "l = timm.create_model('skresnext50_32x4d', pretrained=True, num_classes=1049)\n",
    "l.eval()\n",
    "l = l.cuda()\n",
    "summary(l, input_size=(3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Conv2d-1         [-1, 1024, 14, 14]         787,456\n        PatchEmbed-2            [-1, 196, 1024]               0\n           Dropout-3            [-1, 197, 1024]               0\n         LayerNorm-4            [-1, 197, 1024]           2,048\n            Linear-5            [-1, 197, 3072]       3,148,800\n           Dropout-6         [-1, 16, 197, 197]               0\n            Linear-7            [-1, 197, 1024]       1,049,600\n           Dropout-8            [-1, 197, 1024]               0\n         Attention-9            [-1, 197, 1024]               0\n         Identity-10            [-1, 197, 1024]               0\n        LayerNorm-11            [-1, 197, 1024]           2,048\n           Linear-12            [-1, 197, 4096]       4,198,400\n             GELU-13            [-1, 197, 4096]               0\n          Dropout-14            [-1, 197, 4096]               0\n           Linear-15            [-1, 197, 1024]       4,195,328\n          Dropout-16            [-1, 197, 1024]               0\n              Mlp-17            [-1, 197, 1024]               0\n         Identity-18            [-1, 197, 1024]               0\n            Block-19            [-1, 197, 1024]               0\n        LayerNorm-20            [-1, 197, 1024]           2,048\n           Linear-21            [-1, 197, 3072]       3,148,800\n          Dropout-22         [-1, 16, 197, 197]               0\n           Linear-23            [-1, 197, 1024]       1,049,600\n          Dropout-24            [-1, 197, 1024]               0\n        Attention-25            [-1, 197, 1024]               0\n         Identity-26            [-1, 197, 1024]               0\n        LayerNorm-27            [-1, 197, 1024]           2,048\n           Linear-28            [-1, 197, 4096]       4,198,400\n             GELU-29            [-1, 197, 4096]               0\n          Dropout-30            [-1, 197, 4096]               0\n           Linear-31            [-1, 197, 1024]       4,195,328\n          Dropout-32            [-1, 197, 1024]               0\n              Mlp-33            [-1, 197, 1024]               0\n         Identity-34            [-1, 197, 1024]               0\n            Block-35            [-1, 197, 1024]               0\n        LayerNorm-36            [-1, 197, 1024]           2,048\n           Linear-37            [-1, 197, 3072]       3,148,800\n          Dropout-38         [-1, 16, 197, 197]               0\n           Linear-39            [-1, 197, 1024]       1,049,600\n          Dropout-40            [-1, 197, 1024]               0\n        Attention-41            [-1, 197, 1024]               0\n         Identity-42            [-1, 197, 1024]               0\n        LayerNorm-43            [-1, 197, 1024]           2,048\n           Linear-44            [-1, 197, 4096]       4,198,400\n             GELU-45            [-1, 197, 4096]               0\n          Dropout-46            [-1, 197, 4096]               0\n           Linear-47            [-1, 197, 1024]       4,195,328\n          Dropout-48            [-1, 197, 1024]               0\n              Mlp-49            [-1, 197, 1024]               0\n         Identity-50            [-1, 197, 1024]               0\n            Block-51            [-1, 197, 1024]               0\n        LayerNorm-52            [-1, 197, 1024]           2,048\n           Linear-53            [-1, 197, 3072]       3,148,800\n          Dropout-54         [-1, 16, 197, 197]               0\n           Linear-55            [-1, 197, 1024]       1,049,600\n          Dropout-56            [-1, 197, 1024]               0\n        Attention-57            [-1, 197, 1024]               0\n         Identity-58            [-1, 197, 1024]               0\n        LayerNorm-59            [-1, 197, 1024]           2,048\n           Linear-60            [-1, 197, 4096]       4,198,400\n             GELU-61            [-1, 197, 4096]               0\n          Dropout-62            [-1, 197, 4096]               0\n           Linear-63            [-1, 197, 1024]       4,195,328\n          Dropout-64            [-1, 197, 1024]               0\n              Mlp-65            [-1, 197, 1024]               0\n         Identity-66            [-1, 197, 1024]               0\n            Block-67            [-1, 197, 1024]               0\n        LayerNorm-68            [-1, 197, 1024]           2,048\n           Linear-69            [-1, 197, 3072]       3,148,800\n          Dropout-70         [-1, 16, 197, 197]               0\n           Linear-71            [-1, 197, 1024]       1,049,600\n          Dropout-72            [-1, 197, 1024]               0\n        Attention-73            [-1, 197, 1024]               0\n         Identity-74            [-1, 197, 1024]               0\n        LayerNorm-75            [-1, 197, 1024]           2,048\n           Linear-76            [-1, 197, 4096]       4,198,400\n             GELU-77            [-1, 197, 4096]               0\n          Dropout-78            [-1, 197, 4096]               0\n           Linear-79            [-1, 197, 1024]       4,195,328\n          Dropout-80            [-1, 197, 1024]               0\n              Mlp-81            [-1, 197, 1024]               0\n         Identity-82            [-1, 197, 1024]               0\n            Block-83            [-1, 197, 1024]               0\n        LayerNorm-84            [-1, 197, 1024]           2,048\n           Linear-85            [-1, 197, 3072]       3,148,800\n          Dropout-86         [-1, 16, 197, 197]               0\n           Linear-87            [-1, 197, 1024]       1,049,600\n          Dropout-88            [-1, 197, 1024]               0\n        Attention-89            [-1, 197, 1024]               0\n         Identity-90            [-1, 197, 1024]               0\n        LayerNorm-91            [-1, 197, 1024]           2,048\n           Linear-92            [-1, 197, 4096]       4,198,400\n             GELU-93            [-1, 197, 4096]               0\n          Dropout-94            [-1, 197, 4096]               0\n           Linear-95            [-1, 197, 1024]       4,195,328\n          Dropout-96            [-1, 197, 1024]               0\n              Mlp-97            [-1, 197, 1024]               0\n         Identity-98            [-1, 197, 1024]               0\n            Block-99            [-1, 197, 1024]               0\n       LayerNorm-100            [-1, 197, 1024]           2,048\n          Linear-101            [-1, 197, 3072]       3,148,800\n         Dropout-102         [-1, 16, 197, 197]               0\n          Linear-103            [-1, 197, 1024]       1,049,600\n         Dropout-104            [-1, 197, 1024]               0\n       Attention-105            [-1, 197, 1024]               0\n        Identity-106            [-1, 197, 1024]               0\n       LayerNorm-107            [-1, 197, 1024]           2,048\n          Linear-108            [-1, 197, 4096]       4,198,400\n            GELU-109            [-1, 197, 4096]               0\n         Dropout-110            [-1, 197, 4096]               0\n          Linear-111            [-1, 197, 1024]       4,195,328\n         Dropout-112            [-1, 197, 1024]               0\n             Mlp-113            [-1, 197, 1024]               0\n        Identity-114            [-1, 197, 1024]               0\n           Block-115            [-1, 197, 1024]               0\n       LayerNorm-116            [-1, 197, 1024]           2,048\n          Linear-117            [-1, 197, 3072]       3,148,800\n         Dropout-118         [-1, 16, 197, 197]               0\n          Linear-119            [-1, 197, 1024]       1,049,600\n         Dropout-120            [-1, 197, 1024]               0\n       Attention-121            [-1, 197, 1024]               0\n        Identity-122            [-1, 197, 1024]               0\n       LayerNorm-123            [-1, 197, 1024]           2,048\n          Linear-124            [-1, 197, 4096]       4,198,400\n            GELU-125            [-1, 197, 4096]               0\n         Dropout-126            [-1, 197, 4096]               0\n          Linear-127            [-1, 197, 1024]       4,195,328\n         Dropout-128            [-1, 197, 1024]               0\n             Mlp-129            [-1, 197, 1024]               0\n        Identity-130            [-1, 197, 1024]               0\n           Block-131            [-1, 197, 1024]               0\n       LayerNorm-132            [-1, 197, 1024]           2,048\n          Linear-133            [-1, 197, 3072]       3,148,800\n         Dropout-134         [-1, 16, 197, 197]               0\n          Linear-135            [-1, 197, 1024]       1,049,600\n         Dropout-136            [-1, 197, 1024]               0\n       Attention-137            [-1, 197, 1024]               0\n        Identity-138            [-1, 197, 1024]               0\n       LayerNorm-139            [-1, 197, 1024]           2,048\n          Linear-140            [-1, 197, 4096]       4,198,400\n            GELU-141            [-1, 197, 4096]               0\n         Dropout-142            [-1, 197, 4096]               0\n          Linear-143            [-1, 197, 1024]       4,195,328\n         Dropout-144            [-1, 197, 1024]               0\n             Mlp-145            [-1, 197, 1024]               0\n        Identity-146            [-1, 197, 1024]               0\n           Block-147            [-1, 197, 1024]               0\n       LayerNorm-148            [-1, 197, 1024]           2,048\n          Linear-149            [-1, 197, 3072]       3,148,800\n         Dropout-150         [-1, 16, 197, 197]               0\n          Linear-151            [-1, 197, 1024]       1,049,600\n         Dropout-152            [-1, 197, 1024]               0\n       Attention-153            [-1, 197, 1024]               0\n        Identity-154            [-1, 197, 1024]               0\n       LayerNorm-155            [-1, 197, 1024]           2,048\n          Linear-156            [-1, 197, 4096]       4,198,400\n            GELU-157            [-1, 197, 4096]               0\n         Dropout-158            [-1, 197, 4096]               0\n          Linear-159            [-1, 197, 1024]       4,195,328\n         Dropout-160            [-1, 197, 1024]               0\n             Mlp-161            [-1, 197, 1024]               0\n        Identity-162            [-1, 197, 1024]               0\n           Block-163            [-1, 197, 1024]               0\n       LayerNorm-164            [-1, 197, 1024]           2,048\n          Linear-165            [-1, 197, 3072]       3,148,800\n         Dropout-166         [-1, 16, 197, 197]               0\n          Linear-167            [-1, 197, 1024]       1,049,600\n         Dropout-168            [-1, 197, 1024]               0\n       Attention-169            [-1, 197, 1024]               0\n        Identity-170            [-1, 197, 1024]               0\n       LayerNorm-171            [-1, 197, 1024]           2,048\n          Linear-172            [-1, 197, 4096]       4,198,400\n            GELU-173            [-1, 197, 4096]               0\n         Dropout-174            [-1, 197, 4096]               0\n          Linear-175            [-1, 197, 1024]       4,195,328\n         Dropout-176            [-1, 197, 1024]               0\n             Mlp-177            [-1, 197, 1024]               0\n        Identity-178            [-1, 197, 1024]               0\n           Block-179            [-1, 197, 1024]               0\n       LayerNorm-180            [-1, 197, 1024]           2,048\n          Linear-181            [-1, 197, 3072]       3,148,800\n         Dropout-182         [-1, 16, 197, 197]               0\n          Linear-183            [-1, 197, 1024]       1,049,600\n         Dropout-184            [-1, 197, 1024]               0\n       Attention-185            [-1, 197, 1024]               0\n        Identity-186            [-1, 197, 1024]               0\n       LayerNorm-187            [-1, 197, 1024]           2,048\n          Linear-188            [-1, 197, 4096]       4,198,400\n            GELU-189            [-1, 197, 4096]               0\n         Dropout-190            [-1, 197, 4096]               0\n          Linear-191            [-1, 197, 1024]       4,195,328\n         Dropout-192            [-1, 197, 1024]               0\n             Mlp-193            [-1, 197, 1024]               0\n        Identity-194            [-1, 197, 1024]               0\n           Block-195            [-1, 197, 1024]               0\n       LayerNorm-196            [-1, 197, 1024]           2,048\n          Linear-197            [-1, 197, 3072]       3,148,800\n         Dropout-198         [-1, 16, 197, 197]               0\n          Linear-199            [-1, 197, 1024]       1,049,600\n         Dropout-200            [-1, 197, 1024]               0\n       Attention-201            [-1, 197, 1024]               0\n        Identity-202            [-1, 197, 1024]               0\n       LayerNorm-203            [-1, 197, 1024]           2,048\n          Linear-204            [-1, 197, 4096]       4,198,400\n            GELU-205            [-1, 197, 4096]               0\n         Dropout-206            [-1, 197, 4096]               0\n          Linear-207            [-1, 197, 1024]       4,195,328\n         Dropout-208            [-1, 197, 1024]               0\n             Mlp-209            [-1, 197, 1024]               0\n        Identity-210            [-1, 197, 1024]               0\n           Block-211            [-1, 197, 1024]               0\n       LayerNorm-212            [-1, 197, 1024]           2,048\n          Linear-213            [-1, 197, 3072]       3,148,800\n         Dropout-214         [-1, 16, 197, 197]               0\n          Linear-215            [-1, 197, 1024]       1,049,600\n         Dropout-216            [-1, 197, 1024]               0\n       Attention-217            [-1, 197, 1024]               0\n        Identity-218            [-1, 197, 1024]               0\n       LayerNorm-219            [-1, 197, 1024]           2,048\n          Linear-220            [-1, 197, 4096]       4,198,400\n            GELU-221            [-1, 197, 4096]               0\n         Dropout-222            [-1, 197, 4096]               0\n          Linear-223            [-1, 197, 1024]       4,195,328\n         Dropout-224            [-1, 197, 1024]               0\n             Mlp-225            [-1, 197, 1024]               0\n        Identity-226            [-1, 197, 1024]               0\n           Block-227            [-1, 197, 1024]               0\n       LayerNorm-228            [-1, 197, 1024]           2,048\n          Linear-229            [-1, 197, 3072]       3,148,800\n         Dropout-230         [-1, 16, 197, 197]               0\n          Linear-231            [-1, 197, 1024]       1,049,600\n         Dropout-232            [-1, 197, 1024]               0\n       Attention-233            [-1, 197, 1024]               0\n        Identity-234            [-1, 197, 1024]               0\n       LayerNorm-235            [-1, 197, 1024]           2,048\n          Linear-236            [-1, 197, 4096]       4,198,400\n            GELU-237            [-1, 197, 4096]               0\n         Dropout-238            [-1, 197, 4096]               0\n          Linear-239            [-1, 197, 1024]       4,195,328\n         Dropout-240            [-1, 197, 1024]               0\n             Mlp-241            [-1, 197, 1024]               0\n        Identity-242            [-1, 197, 1024]               0\n           Block-243            [-1, 197, 1024]               0\n       LayerNorm-244            [-1, 197, 1024]           2,048\n          Linear-245            [-1, 197, 3072]       3,148,800\n         Dropout-246         [-1, 16, 197, 197]               0\n          Linear-247            [-1, 197, 1024]       1,049,600\n         Dropout-248            [-1, 197, 1024]               0\n       Attention-249            [-1, 197, 1024]               0\n        Identity-250            [-1, 197, 1024]               0\n       LayerNorm-251            [-1, 197, 1024]           2,048\n          Linear-252            [-1, 197, 4096]       4,198,400\n            GELU-253            [-1, 197, 4096]               0\n         Dropout-254            [-1, 197, 4096]               0\n          Linear-255            [-1, 197, 1024]       4,195,328\n         Dropout-256            [-1, 197, 1024]               0\n             Mlp-257            [-1, 197, 1024]               0\n        Identity-258            [-1, 197, 1024]               0\n           Block-259            [-1, 197, 1024]               0\n       LayerNorm-260            [-1, 197, 1024]           2,048\n          Linear-261            [-1, 197, 3072]       3,148,800\n         Dropout-262         [-1, 16, 197, 197]               0\n          Linear-263            [-1, 197, 1024]       1,049,600\n         Dropout-264            [-1, 197, 1024]               0\n       Attention-265            [-1, 197, 1024]               0\n        Identity-266            [-1, 197, 1024]               0\n       LayerNorm-267            [-1, 197, 1024]           2,048\n          Linear-268            [-1, 197, 4096]       4,198,400\n            GELU-269            [-1, 197, 4096]               0\n         Dropout-270            [-1, 197, 4096]               0\n          Linear-271            [-1, 197, 1024]       4,195,328\n         Dropout-272            [-1, 197, 1024]               0\n             Mlp-273            [-1, 197, 1024]               0\n        Identity-274            [-1, 197, 1024]               0\n           Block-275            [-1, 197, 1024]               0\n       LayerNorm-276            [-1, 197, 1024]           2,048\n          Linear-277            [-1, 197, 3072]       3,148,800\n         Dropout-278         [-1, 16, 197, 197]               0\n          Linear-279            [-1, 197, 1024]       1,049,600\n         Dropout-280            [-1, 197, 1024]               0\n       Attention-281            [-1, 197, 1024]               0\n        Identity-282            [-1, 197, 1024]               0\n       LayerNorm-283            [-1, 197, 1024]           2,048\n          Linear-284            [-1, 197, 4096]       4,198,400\n            GELU-285            [-1, 197, 4096]               0\n         Dropout-286            [-1, 197, 4096]               0\n          Linear-287            [-1, 197, 1024]       4,195,328\n         Dropout-288            [-1, 197, 1024]               0\n             Mlp-289            [-1, 197, 1024]               0\n        Identity-290            [-1, 197, 1024]               0\n           Block-291            [-1, 197, 1024]               0\n       LayerNorm-292            [-1, 197, 1024]           2,048\n          Linear-293            [-1, 197, 3072]       3,148,800\n         Dropout-294         [-1, 16, 197, 197]               0\n          Linear-295            [-1, 197, 1024]       1,049,600\n         Dropout-296            [-1, 197, 1024]               0\n       Attention-297            [-1, 197, 1024]               0\n        Identity-298            [-1, 197, 1024]               0\n       LayerNorm-299            [-1, 197, 1024]           2,048\n          Linear-300            [-1, 197, 4096]       4,198,400\n            GELU-301            [-1, 197, 4096]               0\n         Dropout-302            [-1, 197, 4096]               0\n          Linear-303            [-1, 197, 1024]       4,195,328\n         Dropout-304            [-1, 197, 1024]               0\n             Mlp-305            [-1, 197, 1024]               0\n        Identity-306            [-1, 197, 1024]               0\n           Block-307            [-1, 197, 1024]               0\n       LayerNorm-308            [-1, 197, 1024]           2,048\n          Linear-309            [-1, 197, 3072]       3,148,800\n         Dropout-310         [-1, 16, 197, 197]               0\n          Linear-311            [-1, 197, 1024]       1,049,600\n         Dropout-312            [-1, 197, 1024]               0\n       Attention-313            [-1, 197, 1024]               0\n        Identity-314            [-1, 197, 1024]               0\n       LayerNorm-315            [-1, 197, 1024]           2,048\n          Linear-316            [-1, 197, 4096]       4,198,400\n            GELU-317            [-1, 197, 4096]               0\n         Dropout-318            [-1, 197, 4096]               0\n          Linear-319            [-1, 197, 1024]       4,195,328\n         Dropout-320            [-1, 197, 1024]               0\n             Mlp-321            [-1, 197, 1024]               0\n        Identity-322            [-1, 197, 1024]               0\n           Block-323            [-1, 197, 1024]               0\n       LayerNorm-324            [-1, 197, 1024]           2,048\n          Linear-325            [-1, 197, 3072]       3,148,800\n         Dropout-326         [-1, 16, 197, 197]               0\n          Linear-327            [-1, 197, 1024]       1,049,600\n         Dropout-328            [-1, 197, 1024]               0\n       Attention-329            [-1, 197, 1024]               0\n        Identity-330            [-1, 197, 1024]               0\n       LayerNorm-331            [-1, 197, 1024]           2,048\n          Linear-332            [-1, 197, 4096]       4,198,400\n            GELU-333            [-1, 197, 4096]               0\n         Dropout-334            [-1, 197, 4096]               0\n          Linear-335            [-1, 197, 1024]       4,195,328\n         Dropout-336            [-1, 197, 1024]               0\n             Mlp-337            [-1, 197, 1024]               0\n        Identity-338            [-1, 197, 1024]               0\n           Block-339            [-1, 197, 1024]               0\n       LayerNorm-340            [-1, 197, 1024]           2,048\n          Linear-341            [-1, 197, 3072]       3,148,800\n         Dropout-342         [-1, 16, 197, 197]               0\n          Linear-343            [-1, 197, 1024]       1,049,600\n         Dropout-344            [-1, 197, 1024]               0\n       Attention-345            [-1, 197, 1024]               0\n        Identity-346            [-1, 197, 1024]               0\n       LayerNorm-347            [-1, 197, 1024]           2,048\n          Linear-348            [-1, 197, 4096]       4,198,400\n            GELU-349            [-1, 197, 4096]               0\n         Dropout-350            [-1, 197, 4096]               0\n          Linear-351            [-1, 197, 1024]       4,195,328\n         Dropout-352            [-1, 197, 1024]               0\n             Mlp-353            [-1, 197, 1024]               0\n        Identity-354            [-1, 197, 1024]               0\n           Block-355            [-1, 197, 1024]               0\n       LayerNorm-356            [-1, 197, 1024]           2,048\n          Linear-357            [-1, 197, 3072]       3,148,800\n         Dropout-358         [-1, 16, 197, 197]               0\n          Linear-359            [-1, 197, 1024]       1,049,600\n         Dropout-360            [-1, 197, 1024]               0\n       Attention-361            [-1, 197, 1024]               0\n        Identity-362            [-1, 197, 1024]               0\n       LayerNorm-363            [-1, 197, 1024]           2,048\n          Linear-364            [-1, 197, 4096]       4,198,400\n            GELU-365            [-1, 197, 4096]               0\n         Dropout-366            [-1, 197, 4096]               0\n          Linear-367            [-1, 197, 1024]       4,195,328\n         Dropout-368            [-1, 197, 1024]               0\n             Mlp-369            [-1, 197, 1024]               0\n        Identity-370            [-1, 197, 1024]               0\n           Block-371            [-1, 197, 1024]               0\n       LayerNorm-372            [-1, 197, 1024]           2,048\n          Linear-373            [-1, 197, 3072]       3,148,800\n         Dropout-374         [-1, 16, 197, 197]               0\n          Linear-375            [-1, 197, 1024]       1,049,600\n         Dropout-376            [-1, 197, 1024]               0\n       Attention-377            [-1, 197, 1024]               0\n        Identity-378            [-1, 197, 1024]               0\n       LayerNorm-379            [-1, 197, 1024]           2,048\n          Linear-380            [-1, 197, 4096]       4,198,400\n            GELU-381            [-1, 197, 4096]               0\n         Dropout-382            [-1, 197, 4096]               0\n          Linear-383            [-1, 197, 1024]       4,195,328\n         Dropout-384            [-1, 197, 1024]               0\n             Mlp-385            [-1, 197, 1024]               0\n        Identity-386            [-1, 197, 1024]               0\n           Block-387            [-1, 197, 1024]               0\n       LayerNorm-388            [-1, 197, 1024]           2,048\n          Linear-389                 [-1, 1049]       1,075,225\n================================================================\nTotal params: 304,174,105\nTrainable params: 304,174,105\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 0.57\nForward/backward pass size (MB): 1080.22\nParams size (MB): 1160.33\nEstimated Total Size (MB): 2241.13\n----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "m = timm.create_model('vit_large_patch16_224', pretrained=True, num_classes=1049)\n",
    "m.eval()\n",
    "m = m.cuda()\n",
    "summary(m, input_size=(3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loaded pretrained weights for efficientnet-b1\n----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n         ZeroPad2d-1          [-1, 3, 226, 226]               0\nConv2dStaticSamePadding-2         [-1, 32, 112, 112]             864\n       BatchNorm2d-3         [-1, 32, 112, 112]              64\nMemoryEfficientSwish-4         [-1, 32, 112, 112]               0\n         ZeroPad2d-5         [-1, 32, 114, 114]               0\nConv2dStaticSamePadding-6         [-1, 32, 112, 112]             288\n       BatchNorm2d-7         [-1, 32, 112, 112]              64\nMemoryEfficientSwish-8         [-1, 32, 112, 112]               0\n          Identity-9             [-1, 32, 1, 1]               0\nConv2dStaticSamePadding-10              [-1, 8, 1, 1]             264\nMemoryEfficientSwish-11              [-1, 8, 1, 1]               0\n         Identity-12              [-1, 8, 1, 1]               0\nConv2dStaticSamePadding-13             [-1, 32, 1, 1]             288\n         Identity-14         [-1, 32, 112, 112]               0\nConv2dStaticSamePadding-15         [-1, 16, 112, 112]             512\n      BatchNorm2d-16         [-1, 16, 112, 112]              32\n      MBConvBlock-17         [-1, 16, 112, 112]               0\n        ZeroPad2d-18         [-1, 16, 114, 114]               0\nConv2dStaticSamePadding-19         [-1, 16, 112, 112]             144\n      BatchNorm2d-20         [-1, 16, 112, 112]              32\nMemoryEfficientSwish-21         [-1, 16, 112, 112]               0\n         Identity-22             [-1, 16, 1, 1]               0\nConv2dStaticSamePadding-23              [-1, 4, 1, 1]              68\nMemoryEfficientSwish-24              [-1, 4, 1, 1]               0\n         Identity-25              [-1, 4, 1, 1]               0\nConv2dStaticSamePadding-26             [-1, 16, 1, 1]              80\n         Identity-27         [-1, 16, 112, 112]               0\nConv2dStaticSamePadding-28         [-1, 16, 112, 112]             256\n      BatchNorm2d-29         [-1, 16, 112, 112]              32\n      MBConvBlock-30         [-1, 16, 112, 112]               0\n         Identity-31         [-1, 16, 112, 112]               0\nConv2dStaticSamePadding-32         [-1, 96, 112, 112]           1,536\n      BatchNorm2d-33         [-1, 96, 112, 112]             192\nMemoryEfficientSwish-34         [-1, 96, 112, 112]               0\n        ZeroPad2d-35         [-1, 96, 114, 114]               0\nConv2dStaticSamePadding-36           [-1, 96, 56, 56]             864\n      BatchNorm2d-37           [-1, 96, 56, 56]             192\nMemoryEfficientSwish-38           [-1, 96, 56, 56]               0\n         Identity-39             [-1, 96, 1, 1]               0\nConv2dStaticSamePadding-40              [-1, 4, 1, 1]             388\nMemoryEfficientSwish-41              [-1, 4, 1, 1]               0\n         Identity-42              [-1, 4, 1, 1]               0\nConv2dStaticSamePadding-43             [-1, 96, 1, 1]             480\n         Identity-44           [-1, 96, 56, 56]               0\nConv2dStaticSamePadding-45           [-1, 24, 56, 56]           2,304\n      BatchNorm2d-46           [-1, 24, 56, 56]              48\n      MBConvBlock-47           [-1, 24, 56, 56]               0\n         Identity-48           [-1, 24, 56, 56]               0\nConv2dStaticSamePadding-49          [-1, 144, 56, 56]           3,456\n      BatchNorm2d-50          [-1, 144, 56, 56]             288\nMemoryEfficientSwish-51          [-1, 144, 56, 56]               0\n        ZeroPad2d-52          [-1, 144, 58, 58]               0\nConv2dStaticSamePadding-53          [-1, 144, 56, 56]           1,296\n      BatchNorm2d-54          [-1, 144, 56, 56]             288\nMemoryEfficientSwish-55          [-1, 144, 56, 56]               0\n         Identity-56            [-1, 144, 1, 1]               0\nConv2dStaticSamePadding-57              [-1, 6, 1, 1]             870\nMemoryEfficientSwish-58              [-1, 6, 1, 1]               0\n         Identity-59              [-1, 6, 1, 1]               0\nConv2dStaticSamePadding-60            [-1, 144, 1, 1]           1,008\n         Identity-61          [-1, 144, 56, 56]               0\nConv2dStaticSamePadding-62           [-1, 24, 56, 56]           3,456\n      BatchNorm2d-63           [-1, 24, 56, 56]              48\n      MBConvBlock-64           [-1, 24, 56, 56]               0\n         Identity-65           [-1, 24, 56, 56]               0\nConv2dStaticSamePadding-66          [-1, 144, 56, 56]           3,456\n      BatchNorm2d-67          [-1, 144, 56, 56]             288\nMemoryEfficientSwish-68          [-1, 144, 56, 56]               0\n        ZeroPad2d-69          [-1, 144, 58, 58]               0\nConv2dStaticSamePadding-70          [-1, 144, 56, 56]           1,296\n      BatchNorm2d-71          [-1, 144, 56, 56]             288\nMemoryEfficientSwish-72          [-1, 144, 56, 56]               0\n         Identity-73            [-1, 144, 1, 1]               0\nConv2dStaticSamePadding-74              [-1, 6, 1, 1]             870\nMemoryEfficientSwish-75              [-1, 6, 1, 1]               0\n         Identity-76              [-1, 6, 1, 1]               0\nConv2dStaticSamePadding-77            [-1, 144, 1, 1]           1,008\n         Identity-78          [-1, 144, 56, 56]               0\nConv2dStaticSamePadding-79           [-1, 24, 56, 56]           3,456\n      BatchNorm2d-80           [-1, 24, 56, 56]              48\n      MBConvBlock-81           [-1, 24, 56, 56]               0\n         Identity-82           [-1, 24, 56, 56]               0\nConv2dStaticSamePadding-83          [-1, 144, 56, 56]           3,456\n      BatchNorm2d-84          [-1, 144, 56, 56]             288\nMemoryEfficientSwish-85          [-1, 144, 56, 56]               0\n        ZeroPad2d-86          [-1, 144, 60, 60]               0\nConv2dStaticSamePadding-87          [-1, 144, 28, 28]           3,600\n      BatchNorm2d-88          [-1, 144, 28, 28]             288\nMemoryEfficientSwish-89          [-1, 144, 28, 28]               0\n         Identity-90            [-1, 144, 1, 1]               0\nConv2dStaticSamePadding-91              [-1, 6, 1, 1]             870\nMemoryEfficientSwish-92              [-1, 6, 1, 1]               0\n         Identity-93              [-1, 6, 1, 1]               0\nConv2dStaticSamePadding-94            [-1, 144, 1, 1]           1,008\n         Identity-95          [-1, 144, 28, 28]               0\nConv2dStaticSamePadding-96           [-1, 40, 28, 28]           5,760\n      BatchNorm2d-97           [-1, 40, 28, 28]              80\n      MBConvBlock-98           [-1, 40, 28, 28]               0\n         Identity-99           [-1, 40, 28, 28]               0\nConv2dStaticSamePadding-100          [-1, 240, 28, 28]           9,600\n     BatchNorm2d-101          [-1, 240, 28, 28]             480\nMemoryEfficientSwish-102          [-1, 240, 28, 28]               0\n       ZeroPad2d-103          [-1, 240, 32, 32]               0\nConv2dStaticSamePadding-104          [-1, 240, 28, 28]           6,000\n     BatchNorm2d-105          [-1, 240, 28, 28]             480\nMemoryEfficientSwish-106          [-1, 240, 28, 28]               0\n        Identity-107            [-1, 240, 1, 1]               0\nConv2dStaticSamePadding-108             [-1, 10, 1, 1]           2,410\nMemoryEfficientSwish-109             [-1, 10, 1, 1]               0\n        Identity-110             [-1, 10, 1, 1]               0\nConv2dStaticSamePadding-111            [-1, 240, 1, 1]           2,640\n        Identity-112          [-1, 240, 28, 28]               0\nConv2dStaticSamePadding-113           [-1, 40, 28, 28]           9,600\n     BatchNorm2d-114           [-1, 40, 28, 28]              80\n     MBConvBlock-115           [-1, 40, 28, 28]               0\n        Identity-116           [-1, 40, 28, 28]               0\nConv2dStaticSamePadding-117          [-1, 240, 28, 28]           9,600\n     BatchNorm2d-118          [-1, 240, 28, 28]             480\nMemoryEfficientSwish-119          [-1, 240, 28, 28]               0\n       ZeroPad2d-120          [-1, 240, 32, 32]               0\nConv2dStaticSamePadding-121          [-1, 240, 28, 28]           6,000\n     BatchNorm2d-122          [-1, 240, 28, 28]             480\nMemoryEfficientSwish-123          [-1, 240, 28, 28]               0\n        Identity-124            [-1, 240, 1, 1]               0\nConv2dStaticSamePadding-125             [-1, 10, 1, 1]           2,410\nMemoryEfficientSwish-126             [-1, 10, 1, 1]               0\n        Identity-127             [-1, 10, 1, 1]               0\nConv2dStaticSamePadding-128            [-1, 240, 1, 1]           2,640\n        Identity-129          [-1, 240, 28, 28]               0\nConv2dStaticSamePadding-130           [-1, 40, 28, 28]           9,600\n     BatchNorm2d-131           [-1, 40, 28, 28]              80\n     MBConvBlock-132           [-1, 40, 28, 28]               0\n        Identity-133           [-1, 40, 28, 28]               0\nConv2dStaticSamePadding-134          [-1, 240, 28, 28]           9,600\n     BatchNorm2d-135          [-1, 240, 28, 28]             480\nMemoryEfficientSwish-136          [-1, 240, 28, 28]               0\n       ZeroPad2d-137          [-1, 240, 30, 30]               0\nConv2dStaticSamePadding-138          [-1, 240, 14, 14]           2,160\n     BatchNorm2d-139          [-1, 240, 14, 14]             480\nMemoryEfficientSwish-140          [-1, 240, 14, 14]               0\n        Identity-141            [-1, 240, 1, 1]               0\nConv2dStaticSamePadding-142             [-1, 10, 1, 1]           2,410\nMemoryEfficientSwish-143             [-1, 10, 1, 1]               0\n        Identity-144             [-1, 10, 1, 1]               0\nConv2dStaticSamePadding-145            [-1, 240, 1, 1]           2,640\n        Identity-146          [-1, 240, 14, 14]               0\nConv2dStaticSamePadding-147           [-1, 80, 14, 14]          19,200\n     BatchNorm2d-148           [-1, 80, 14, 14]             160\n     MBConvBlock-149           [-1, 80, 14, 14]               0\n        Identity-150           [-1, 80, 14, 14]               0\nConv2dStaticSamePadding-151          [-1, 480, 14, 14]          38,400\n     BatchNorm2d-152          [-1, 480, 14, 14]             960\nMemoryEfficientSwish-153          [-1, 480, 14, 14]               0\n       ZeroPad2d-154          [-1, 480, 16, 16]               0\nConv2dStaticSamePadding-155          [-1, 480, 14, 14]           4,320\n     BatchNorm2d-156          [-1, 480, 14, 14]             960\nMemoryEfficientSwish-157          [-1, 480, 14, 14]               0\n        Identity-158            [-1, 480, 1, 1]               0\nConv2dStaticSamePadding-159             [-1, 20, 1, 1]           9,620\nMemoryEfficientSwish-160             [-1, 20, 1, 1]               0\n        Identity-161             [-1, 20, 1, 1]               0\nConv2dStaticSamePadding-162            [-1, 480, 1, 1]          10,080\n        Identity-163          [-1, 480, 14, 14]               0\nConv2dStaticSamePadding-164           [-1, 80, 14, 14]          38,400\n     BatchNorm2d-165           [-1, 80, 14, 14]             160\n     MBConvBlock-166           [-1, 80, 14, 14]               0\n        Identity-167           [-1, 80, 14, 14]               0\nConv2dStaticSamePadding-168          [-1, 480, 14, 14]          38,400\n     BatchNorm2d-169          [-1, 480, 14, 14]             960\nMemoryEfficientSwish-170          [-1, 480, 14, 14]               0\n       ZeroPad2d-171          [-1, 480, 16, 16]               0\nConv2dStaticSamePadding-172          [-1, 480, 14, 14]           4,320\n     BatchNorm2d-173          [-1, 480, 14, 14]             960\nMemoryEfficientSwish-174          [-1, 480, 14, 14]               0\n        Identity-175            [-1, 480, 1, 1]               0\nConv2dStaticSamePadding-176             [-1, 20, 1, 1]           9,620\nMemoryEfficientSwish-177             [-1, 20, 1, 1]               0\n        Identity-178             [-1, 20, 1, 1]               0\nConv2dStaticSamePadding-179            [-1, 480, 1, 1]          10,080\n        Identity-180          [-1, 480, 14, 14]               0\nConv2dStaticSamePadding-181           [-1, 80, 14, 14]          38,400\n     BatchNorm2d-182           [-1, 80, 14, 14]             160\n     MBConvBlock-183           [-1, 80, 14, 14]               0\n        Identity-184           [-1, 80, 14, 14]               0\nConv2dStaticSamePadding-185          [-1, 480, 14, 14]          38,400\n     BatchNorm2d-186          [-1, 480, 14, 14]             960\nMemoryEfficientSwish-187          [-1, 480, 14, 14]               0\n       ZeroPad2d-188          [-1, 480, 16, 16]               0\nConv2dStaticSamePadding-189          [-1, 480, 14, 14]           4,320\n     BatchNorm2d-190          [-1, 480, 14, 14]             960\nMemoryEfficientSwish-191          [-1, 480, 14, 14]               0\n        Identity-192            [-1, 480, 1, 1]               0\nConv2dStaticSamePadding-193             [-1, 20, 1, 1]           9,620\nMemoryEfficientSwish-194             [-1, 20, 1, 1]               0\n        Identity-195             [-1, 20, 1, 1]               0\nConv2dStaticSamePadding-196            [-1, 480, 1, 1]          10,080\n        Identity-197          [-1, 480, 14, 14]               0\nConv2dStaticSamePadding-198           [-1, 80, 14, 14]          38,400\n     BatchNorm2d-199           [-1, 80, 14, 14]             160\n     MBConvBlock-200           [-1, 80, 14, 14]               0\n        Identity-201           [-1, 80, 14, 14]               0\nConv2dStaticSamePadding-202          [-1, 480, 14, 14]          38,400\n     BatchNorm2d-203          [-1, 480, 14, 14]             960\nMemoryEfficientSwish-204          [-1, 480, 14, 14]               0\n       ZeroPad2d-205          [-1, 480, 18, 18]               0\nConv2dStaticSamePadding-206          [-1, 480, 14, 14]          12,000\n     BatchNorm2d-207          [-1, 480, 14, 14]             960\nMemoryEfficientSwish-208          [-1, 480, 14, 14]               0\n        Identity-209            [-1, 480, 1, 1]               0\nConv2dStaticSamePadding-210             [-1, 20, 1, 1]           9,620\nMemoryEfficientSwish-211             [-1, 20, 1, 1]               0\n        Identity-212             [-1, 20, 1, 1]               0\nConv2dStaticSamePadding-213            [-1, 480, 1, 1]          10,080\n        Identity-214          [-1, 480, 14, 14]               0\nConv2dStaticSamePadding-215          [-1, 112, 14, 14]          53,760\n     BatchNorm2d-216          [-1, 112, 14, 14]             224\n     MBConvBlock-217          [-1, 112, 14, 14]               0\n        Identity-218          [-1, 112, 14, 14]               0\nConv2dStaticSamePadding-219          [-1, 672, 14, 14]          75,264\n     BatchNorm2d-220          [-1, 672, 14, 14]           1,344\nMemoryEfficientSwish-221          [-1, 672, 14, 14]               0\n       ZeroPad2d-222          [-1, 672, 18, 18]               0\nConv2dStaticSamePadding-223          [-1, 672, 14, 14]          16,800\n     BatchNorm2d-224          [-1, 672, 14, 14]           1,344\nMemoryEfficientSwish-225          [-1, 672, 14, 14]               0\n        Identity-226            [-1, 672, 1, 1]               0\nConv2dStaticSamePadding-227             [-1, 28, 1, 1]          18,844\nMemoryEfficientSwish-228             [-1, 28, 1, 1]               0\n        Identity-229             [-1, 28, 1, 1]               0\nConv2dStaticSamePadding-230            [-1, 672, 1, 1]          19,488\n        Identity-231          [-1, 672, 14, 14]               0\nConv2dStaticSamePadding-232          [-1, 112, 14, 14]          75,264\n     BatchNorm2d-233          [-1, 112, 14, 14]             224\n     MBConvBlock-234          [-1, 112, 14, 14]               0\n        Identity-235          [-1, 112, 14, 14]               0\nConv2dStaticSamePadding-236          [-1, 672, 14, 14]          75,264\n     BatchNorm2d-237          [-1, 672, 14, 14]           1,344\nMemoryEfficientSwish-238          [-1, 672, 14, 14]               0\n       ZeroPad2d-239          [-1, 672, 18, 18]               0\nConv2dStaticSamePadding-240          [-1, 672, 14, 14]          16,800\n     BatchNorm2d-241          [-1, 672, 14, 14]           1,344\nMemoryEfficientSwish-242          [-1, 672, 14, 14]               0\n        Identity-243            [-1, 672, 1, 1]               0\nConv2dStaticSamePadding-244             [-1, 28, 1, 1]          18,844\nMemoryEfficientSwish-245             [-1, 28, 1, 1]               0\n        Identity-246             [-1, 28, 1, 1]               0\nConv2dStaticSamePadding-247            [-1, 672, 1, 1]          19,488\n        Identity-248          [-1, 672, 14, 14]               0\nConv2dStaticSamePadding-249          [-1, 112, 14, 14]          75,264\n     BatchNorm2d-250          [-1, 112, 14, 14]             224\n     MBConvBlock-251          [-1, 112, 14, 14]               0\n        Identity-252          [-1, 112, 14, 14]               0\nConv2dStaticSamePadding-253          [-1, 672, 14, 14]          75,264\n     BatchNorm2d-254          [-1, 672, 14, 14]           1,344\nMemoryEfficientSwish-255          [-1, 672, 14, 14]               0\n       ZeroPad2d-256          [-1, 672, 18, 18]               0\nConv2dStaticSamePadding-257          [-1, 672, 14, 14]          16,800\n     BatchNorm2d-258          [-1, 672, 14, 14]           1,344\nMemoryEfficientSwish-259          [-1, 672, 14, 14]               0\n        Identity-260            [-1, 672, 1, 1]               0\nConv2dStaticSamePadding-261             [-1, 28, 1, 1]          18,844\nMemoryEfficientSwish-262             [-1, 28, 1, 1]               0\n        Identity-263             [-1, 28, 1, 1]               0\nConv2dStaticSamePadding-264            [-1, 672, 1, 1]          19,488\n        Identity-265          [-1, 672, 14, 14]               0\nConv2dStaticSamePadding-266          [-1, 112, 14, 14]          75,264\n     BatchNorm2d-267          [-1, 112, 14, 14]             224\n     MBConvBlock-268          [-1, 112, 14, 14]               0\n        Identity-269          [-1, 112, 14, 14]               0\nConv2dStaticSamePadding-270          [-1, 672, 14, 14]          75,264\n     BatchNorm2d-271          [-1, 672, 14, 14]           1,344\nMemoryEfficientSwish-272          [-1, 672, 14, 14]               0\n       ZeroPad2d-273          [-1, 672, 18, 18]               0\nConv2dStaticSamePadding-274            [-1, 672, 7, 7]          16,800\n     BatchNorm2d-275            [-1, 672, 7, 7]           1,344\nMemoryEfficientSwish-276            [-1, 672, 7, 7]               0\n        Identity-277            [-1, 672, 1, 1]               0\nConv2dStaticSamePadding-278             [-1, 28, 1, 1]          18,844\nMemoryEfficientSwish-279             [-1, 28, 1, 1]               0\n        Identity-280             [-1, 28, 1, 1]               0\nConv2dStaticSamePadding-281            [-1, 672, 1, 1]          19,488\n        Identity-282            [-1, 672, 7, 7]               0\nConv2dStaticSamePadding-283            [-1, 192, 7, 7]         129,024\n     BatchNorm2d-284            [-1, 192, 7, 7]             384\n     MBConvBlock-285            [-1, 192, 7, 7]               0\n        Identity-286            [-1, 192, 7, 7]               0\nConv2dStaticSamePadding-287           [-1, 1152, 7, 7]         221,184\n     BatchNorm2d-288           [-1, 1152, 7, 7]           2,304\nMemoryEfficientSwish-289           [-1, 1152, 7, 7]               0\n       ZeroPad2d-290         [-1, 1152, 11, 11]               0\nConv2dStaticSamePadding-291           [-1, 1152, 7, 7]          28,800\n     BatchNorm2d-292           [-1, 1152, 7, 7]           2,304\nMemoryEfficientSwish-293           [-1, 1152, 7, 7]               0\n        Identity-294           [-1, 1152, 1, 1]               0\nConv2dStaticSamePadding-295             [-1, 48, 1, 1]          55,344\nMemoryEfficientSwish-296             [-1, 48, 1, 1]               0\n        Identity-297             [-1, 48, 1, 1]               0\nConv2dStaticSamePadding-298           [-1, 1152, 1, 1]          56,448\n        Identity-299           [-1, 1152, 7, 7]               0\nConv2dStaticSamePadding-300            [-1, 192, 7, 7]         221,184\n     BatchNorm2d-301            [-1, 192, 7, 7]             384\n     MBConvBlock-302            [-1, 192, 7, 7]               0\n        Identity-303            [-1, 192, 7, 7]               0\nConv2dStaticSamePadding-304           [-1, 1152, 7, 7]         221,184\n     BatchNorm2d-305           [-1, 1152, 7, 7]           2,304\nMemoryEfficientSwish-306           [-1, 1152, 7, 7]               0\n       ZeroPad2d-307         [-1, 1152, 11, 11]               0\nConv2dStaticSamePadding-308           [-1, 1152, 7, 7]          28,800\n     BatchNorm2d-309           [-1, 1152, 7, 7]           2,304\nMemoryEfficientSwish-310           [-1, 1152, 7, 7]               0\n        Identity-311           [-1, 1152, 1, 1]               0\nConv2dStaticSamePadding-312             [-1, 48, 1, 1]          55,344\nMemoryEfficientSwish-313             [-1, 48, 1, 1]               0\n        Identity-314             [-1, 48, 1, 1]               0\nConv2dStaticSamePadding-315           [-1, 1152, 1, 1]          56,448\n        Identity-316           [-1, 1152, 7, 7]               0\nConv2dStaticSamePadding-317            [-1, 192, 7, 7]         221,184\n     BatchNorm2d-318            [-1, 192, 7, 7]             384\n     MBConvBlock-319            [-1, 192, 7, 7]               0\n        Identity-320            [-1, 192, 7, 7]               0\nConv2dStaticSamePadding-321           [-1, 1152, 7, 7]         221,184\n     BatchNorm2d-322           [-1, 1152, 7, 7]           2,304\nMemoryEfficientSwish-323           [-1, 1152, 7, 7]               0\n       ZeroPad2d-324         [-1, 1152, 11, 11]               0\nConv2dStaticSamePadding-325           [-1, 1152, 7, 7]          28,800\n     BatchNorm2d-326           [-1, 1152, 7, 7]           2,304\nMemoryEfficientSwish-327           [-1, 1152, 7, 7]               0\n        Identity-328           [-1, 1152, 1, 1]               0\nConv2dStaticSamePadding-329             [-1, 48, 1, 1]          55,344\nMemoryEfficientSwish-330             [-1, 48, 1, 1]               0\n        Identity-331             [-1, 48, 1, 1]               0\nConv2dStaticSamePadding-332           [-1, 1152, 1, 1]          56,448\n        Identity-333           [-1, 1152, 7, 7]               0\nConv2dStaticSamePadding-334            [-1, 192, 7, 7]         221,184\n     BatchNorm2d-335            [-1, 192, 7, 7]             384\n     MBConvBlock-336            [-1, 192, 7, 7]               0\n        Identity-337            [-1, 192, 7, 7]               0\nConv2dStaticSamePadding-338           [-1, 1152, 7, 7]         221,184\n     BatchNorm2d-339           [-1, 1152, 7, 7]           2,304\nMemoryEfficientSwish-340           [-1, 1152, 7, 7]               0\n       ZeroPad2d-341         [-1, 1152, 11, 11]               0\nConv2dStaticSamePadding-342           [-1, 1152, 7, 7]          28,800\n     BatchNorm2d-343           [-1, 1152, 7, 7]           2,304\nMemoryEfficientSwish-344           [-1, 1152, 7, 7]               0\n        Identity-345           [-1, 1152, 1, 1]               0\nConv2dStaticSamePadding-346             [-1, 48, 1, 1]          55,344\nMemoryEfficientSwish-347             [-1, 48, 1, 1]               0\n        Identity-348             [-1, 48, 1, 1]               0\nConv2dStaticSamePadding-349           [-1, 1152, 1, 1]          56,448\n        Identity-350           [-1, 1152, 7, 7]               0\nConv2dStaticSamePadding-351            [-1, 192, 7, 7]         221,184\n     BatchNorm2d-352            [-1, 192, 7, 7]             384\n     MBConvBlock-353            [-1, 192, 7, 7]               0\n        Identity-354            [-1, 192, 7, 7]               0\nConv2dStaticSamePadding-355           [-1, 1152, 7, 7]         221,184\n     BatchNorm2d-356           [-1, 1152, 7, 7]           2,304\nMemoryEfficientSwish-357           [-1, 1152, 7, 7]               0\n       ZeroPad2d-358           [-1, 1152, 9, 9]               0\nConv2dStaticSamePadding-359           [-1, 1152, 7, 7]          10,368\n     BatchNorm2d-360           [-1, 1152, 7, 7]           2,304\nMemoryEfficientSwish-361           [-1, 1152, 7, 7]               0\n        Identity-362           [-1, 1152, 1, 1]               0\nConv2dStaticSamePadding-363             [-1, 48, 1, 1]          55,344\nMemoryEfficientSwish-364             [-1, 48, 1, 1]               0\n        Identity-365             [-1, 48, 1, 1]               0\nConv2dStaticSamePadding-366           [-1, 1152, 1, 1]          56,448\n        Identity-367           [-1, 1152, 7, 7]               0\nConv2dStaticSamePadding-368            [-1, 320, 7, 7]         368,640\n     BatchNorm2d-369            [-1, 320, 7, 7]             640\n     MBConvBlock-370            [-1, 320, 7, 7]               0\n        Identity-371            [-1, 320, 7, 7]               0\nConv2dStaticSamePadding-372           [-1, 1920, 7, 7]         614,400\n     BatchNorm2d-373           [-1, 1920, 7, 7]           3,840\nMemoryEfficientSwish-374           [-1, 1920, 7, 7]               0\n       ZeroPad2d-375           [-1, 1920, 9, 9]               0\nConv2dStaticSamePadding-376           [-1, 1920, 7, 7]          17,280\n     BatchNorm2d-377           [-1, 1920, 7, 7]           3,840\nMemoryEfficientSwish-378           [-1, 1920, 7, 7]               0\n        Identity-379           [-1, 1920, 1, 1]               0\nConv2dStaticSamePadding-380             [-1, 80, 1, 1]         153,680\nMemoryEfficientSwish-381             [-1, 80, 1, 1]               0\n        Identity-382             [-1, 80, 1, 1]               0\nConv2dStaticSamePadding-383           [-1, 1920, 1, 1]         155,520\n        Identity-384           [-1, 1920, 7, 7]               0\nConv2dStaticSamePadding-385            [-1, 320, 7, 7]         614,400\n     BatchNorm2d-386            [-1, 320, 7, 7]             640\n     MBConvBlock-387            [-1, 320, 7, 7]               0\n        Identity-388            [-1, 320, 7, 7]               0\nConv2dStaticSamePadding-389           [-1, 1280, 7, 7]         409,600\n     BatchNorm2d-390           [-1, 1280, 7, 7]           2,560\nMemoryEfficientSwish-391           [-1, 1280, 7, 7]               0\nAdaptiveAvgPool2d-392           [-1, 1280, 1, 1]               0\n         Dropout-393                 [-1, 1280]               0\n          Linear-394                 [-1, 1049]       1,343,769\n================================================================\nTotal params: 7,856,953\nTrainable params: 7,856,953\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 0.57\nForward/backward pass size (MB): 295.62\nParams size (MB): 29.97\nEstimated Total Size (MB): 326.17\n----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "n = EfficientNet.from_pretrained(\"efficientnet-b1\", num_classes=1049)\n",
    "n.eval()\n",
    "n = n.cuda()\n",
    "summary(n, input_size=(3, 224, 224))        "
   ]
  },
  {
   "source": [
    "* EfficientNet-b1 : 7,856,953\n",
    "* Vit_base_16 : 86,453,273\n",
    "* Vit_base_res26d_16 : 101,374,073\n",
    "* Vit_large_16 : 304,174,105\n",
    "* Sk_resnext50_32x4d : 27,580,185"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('LANDMARK': conda)",
   "language": "python",
   "name": "python38564bitlandmarkcondadba7afad6e4e4d0bb74bdc57cae63807"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}